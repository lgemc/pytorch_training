{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model fine tune: beyond prompting only\n",
    "\n",
    "Now we are going to fine tune a llama model using the train and test datasets we have created.\n",
    "\n",
    "1. Load the datasets for training and evaluation\n",
    "2. Define the model and tokenizer\n",
    "3. Set up the training configuration using `peft` for LoRA\n",
    "4. Train the model using the `Trainer` class from `transformers`\n",
    "5. Save the trained model and tokenizer"
   ],
   "id": "94ab066a188de36b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The finetune dataset\n",
    "\n",
    "We have a dataset pushed to hugging face hub with the next structure:\n",
    "\n",
    "You are an expert AI specializing in multiple-choice questions.\n",
    "\n",
    "```\n",
    "Your task is to analyze the provided context, question, and options, then identify the single best answer.\\nRespond with only the capital letter (A, B, C, or D) corresponding to your choice.\n",
    "\n",
    "Context:\n",
    "\n",
    "{{context}}\n",
    "\n",
    "Question:\n",
    "\n",
    "{{question}}\n",
    "\n",
    "Options:\n",
    "\n",
    "A) {{options[0]}}\n",
    "B) {{options[1]}}\n",
    "C) {{options[2]}}\n",
    "D) {{options[3]}}\n",
    "\n",
    "Answer: B\n",
    "```\n"
   ],
   "id": "c223ecf4cf8b8d5a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T01:14:23.322654Z",
     "start_time": "2025-05-26T01:14:23.317217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset as HFDataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # Disable Weights & Biases logging because it is not needed for this task"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:04:23.605128Z",
     "start_time": "2025-05-26T01:04:23.596708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "id": "acab34632fcbdd4c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:17:49.131835Z",
     "start_time": "2025-05-26T01:17:48.429908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "id": "207d952987db3981",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "questions = DatasetDict.load_from_disk(\"maia-pln-2025/pubmed_QA\")\n",
    "eval_questions = DatasetDict.load_from_disk(\"maia-pln-2025/pubmed_QA_test_questions\")"
   ],
   "id": "714bffe53d3ced32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:22:52.637446Z",
     "start_time": "2025-05-26T01:22:52.610375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainAndEval(Dataset):\n",
    "    \"\"\"\n",
    "    This loads a map which contains:\n",
    "    - \"id\"\n",
    "    - \"excerpt\"\n",
    "    - \"question\"\n",
    "    - \"statement\": the correct option\n",
    "    - \"distractors\"\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self._raw_data = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                self._raw_data.append(line.strip())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._raw_data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return json.loads(self._raw_data[idx])\n",
    "\n",
    "class EvalWithAnswers(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that takes a TrainAndEval dataset and adds the statement to the distractors\n",
    "    to create a multiple choice question. The statement is inserted at a random position\n",
    "    in the distractors.\n",
    "\n",
    "    Returns two item keys: options and answer_idx.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: TrainAndEval):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        options = item[\"distractors\"]\n",
    "        # insert the statement at any random position in the options\n",
    "        index = random.randint(0, len(options))\n",
    "        options.insert(index, item[\"statement\"])\n",
    "\n",
    "        item[\"options\"] = options\n",
    "        item[\"answer_idx\"] = index\n",
    "\n",
    "        return item\n",
    "\n",
    "OPTIONS =  ['A', 'B', 'C', 'D']\n",
    "\n",
    "class Prompted(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: EvalWithAnswers,\n",
    "            prompter: Callable,\n",
    "            options: list = OPTIONS,\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.prompter = prompter\n",
    "        self.options = options\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item = self.dataset[item]\n",
    "        answer = item[\"answer_idx\"]\n",
    "        options = item[\"options\"]\n",
    "        context = item[\"excerpt\"]\n",
    "        question = item[\"question\"]\n",
    "\n",
    "        item[\"text\"] = self.prompter(question, context, options, index_to_answer(answer, self.options))\n",
    "\n",
    "        return item\n",
    "\n",
    "class Tokenized(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that takes a TrainAndEval dataset and adds the statement to the distractors\n",
    "    to create a multiple choice question. The statement is inserted at a random position\n",
    "    in the distractors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, dataset: Prompted, max_length: int = 1200):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        # Tokenize the input text and mask tokens before the answer_start_text\n",
    "        tokenized = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=1200,\n",
    "            return_attention_mask=True,\n",
    "            truncation_strategy=\"longest_first\",  # Safe fallback\n",
    "        )\n",
    "\n",
    "        item[\"input_ids\"] = tokenized[\"input_ids\"][0]  # Remove batch dimension\n",
    "        item[\"attention_mask\"] = tokenized[\"attention_mask\"][0]\n",
    "        item[\"labels\"] = tokenized[\"input_ids\"][0]\n",
    "\n",
    "\n",
    "        return item\n",
    "\n",
    "def index_to_answer(index: int, options: list) -> str:\n",
    "    \"\"\"\n",
    "    Convert an index to an answer string.\n",
    "    \"\"\"\n",
    "    return options[index]\n",
    "\n",
    "\n",
    "def to_transformers_dataset(dataset: Prompted) -> HFDataset:\n",
    "    data = [dataset[i] for i in range(len(dataset))]\n",
    "    hf_dataset = HFDataset.from_list(data)\n",
    "\n",
    "    return hf_dataset\n",
    "\n",
    "def generate_prompt(\n",
    "    question: str,\n",
    "    context: str,\n",
    "    options: list[str],\n",
    "    answer: str = None\n",
    ") -> str:\n",
    "    options = \"\\n\".join([f\"{chr(65 + i)}) {option}\" for i, option in enumerate(options)])\n",
    "    prompt = f\"\"\"You are an expert AI specializing in multiple-choice questions.\n",
    "Your task is to analyze the provided context, question, and options, then identify the single best answer.\n",
    "Respond with only the capital letter (A, B, C, or D) corresponding to your choice.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Options:\n",
    "{options}\n",
    "\n",
    "Answer: {answer}\"\"\"\n",
    "    return prompt"
   ],
   "id": "65ada5bcc81106ef",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:22:53.232809Z",
     "start_time": "2025-05-26T01:22:53.208460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_dataset = TrainAndEval(\"./data/pubmed_QA_eval.json\")\n",
    "eval_with_answers = EvalWithAnswers(eval_dataset)\n",
    "eval_prompted = Prompted(eval_with_answers, prompter=generate_prompt)\n",
    "eval_tokenized = Tokenized(\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=eval_prompted,\n",
    "    max_length=1200\n",
    ")"
   ],
   "id": "ee802b1f3701a70",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:22:53.787558Z",
     "start_time": "2025-05-26T01:22:53.721640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TrainAndEval(\"./data/pubmed_QA_train.json\")\n",
    "train_with_answers = EvalWithAnswers(train_dataset)\n",
    "train_prompted = Prompted(train_with_answers, prompter=generate_prompt)\n",
    "train_tokenized = Tokenized(\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=train_prompted,\n",
    "    max_length=1200\n",
    ")"
   ],
   "id": "7191a85153ddc6a6",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:22:54.543555Z",
     "start_time": "2025-05-26T01:22:54.535213Z"
    }
   },
   "cell_type": "code",
   "source": "eval_prompted[0][\"text\"] # check the first item in the eval dataset",
   "id": "375ba1f68d554c1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert AI specializing in multiple-choice questions.\\nYour task is to analyze the provided context, question, and options, then identify the single best answer.\\nRespond with only the capital letter (A, B, C, or D) corresponding to your choice.\\n\\nContext:\\nTemporal changes in medial basal hypothalamic LH-RH correlated with plasma LH during the rat estrous cycle and following electrochemical stimulation of the medial preoptic area in pentobarbital-treated proestrous rats. In the present studies we have simultaneously measured changes in medial basal hypothalamic (MBH) leutenizing hormone-releasing hormone (LH-RH) and in plasma LH by radioimmunoassay in female rats at various hours during the 4-day estrous cycle and under experimental conditions known to alter pituitary LH secretion. In groups of rats decapitated at 12.00 h and 15.00 h on estrus and diestrus, plasma LH remained at basal levels (5-8 ng/ml) and MBH-LH-RH concentrations showed average steady state concentrations of 2231 +/- 205 pg/mg. On the day of proestrus hourly measurements of MBH-LH-RH between 12.00 h and 21.00 h suggested rhythmic rises and falls in the decapeptide concomitant with rises and falls in plasma LH. In a second group of pentobarbital-anesthetized proestrous rats a significant decline in MBH-LH-RH occurred (to 573 +/- 137 pg/mg) which then remained at low concentrations between 14.00 h and 18.00 h proestrus. Following bilateral preoptic area (MPOA) electrochemical stimulation of pentobarbital-treated proestrous rats, LH was significantly increased by 30 min, peaked between 90-120 min and returned to basal levels by 210 min poststimulation. In the same animals within 15 min poststimulation, MBH-LH-RH increased from the basal concentrations noted after pentobarbital anesthesia to elevated levels comparable to those observed throughout estrus, diestrus and on proestrous morning. Further, as plasma LH rose to peak concentrations and declined to basal plasma values, rhythmic rises and falls in MBH-LH-RH were observed with intervals between pulses of approximately 60 min. Seemingly, hypothalamic LH-RH is released as pulsatile pulses from a releasable pool; this pool is replenished and again LH-RH is discharged in response to constant stimulation by the preoptic brain.\\n\\nQuestion:\\nWhat relationship exists between medial basal hypothalamic LH-RH levels and plasma LH changes during the rat estrous cycle and after stimulation of the medial preoptic area?\\n\\nOptions:\\nA) Medial basal hypothalamic LH-RH levels remain constant throughout the rat estrous cycle and do not affect plasma LH changes.\\nB) Temporal fluctuations in medial basal hypothalamic LH-RH levels correlate with plasma LH changes during the rat estrous cycle and following stimulation of the medial preoptic area.\\nC) There is no relationship between medial basal hypothalamic LH-RH levels and plasma LH changes during the rat estrous cycle.\\nD) Increased medial basal hypothalamic LH-RH levels lead to a decrease in plasma LH during the rat estrous cycle.\\n\\nAnswer: B'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:22:55.358151Z",
     "start_time": "2025-05-26T01:22:55.343677Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(eval_tokenized[0][\"labels\"], skip_special_tokens=True) # check the first item in the eval dataset after tokenization",
   "id": "5794155de46268e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert AI specializing in multiple-choice questions.\\nYour task is to analyze the provided context, question, and options, then identify the single best answer.\\nRespond with only the capital letter (A, B, C, or D) corresponding to your choice.\\n\\nContext:\\nTemporal changes in medial basal hypothalamic LH-RH correlated with plasma LH during the rat estrous cycle and following electrochemical stimulation of the medial preoptic area in pentobarbital-treated proestrous rats. In the present studies we have simultaneously measured changes in medial basal hypothalamic (MBH) leutenizing hormone-releasing hormone (LH-RH) and in plasma LH by radioimmunoassay in female rats at various hours during the 4-day estrous cycle and under experimental conditions known to alter pituitary LH secretion. In groups of rats decapitated at 12.00 h and 15.00 h on estrus and diestrus, plasma LH remained at basal levels (5-8 ng/ml) and MBH-LH-RH concentrations showed average steady state concentrations of 2231 +/- 205 pg/mg. On the day of proestrus hourly measurements of MBH-LH-RH between 12.00 h and 21.00 h suggested rhythmic rises and falls in the decapeptide concomitant with rises and falls in plasma LH. In a second group of pentobarbital-anesthetized proestrous rats a significant decline in MBH-LH-RH occurred (to 573 +/- 137 pg/mg) which then remained at low concentrations between 14.00 h and 18.00 h proestrus. Following bilateral preoptic area (MPOA) electrochemical stimulation of pentobarbital-treated proestrous rats, LH was significantly increased by 30 min, peaked between 90-120 min and returned to basal levels by 210 min poststimulation. In the same animals within 15 min poststimulation, MBH-LH-RH increased from the basal concentrations noted after pentobarbital anesthesia to elevated levels comparable to those observed throughout estrus, diestrus and on proestrous morning. Further, as plasma LH rose to peak concentrations and declined to basal plasma values, rhythmic rises and falls in MBH-LH-RH were observed with intervals between pulses of approximately 60 min. Seemingly, hypothalamic LH-RH is released as pulsatile pulses from a releasable pool; this pool is replenished and again LH-RH is discharged in response to constant stimulation by the preoptic brain.\\n\\nQuestion:\\nWhat relationship exists between medial basal hypothalamic LH-RH levels and plasma LH changes during the rat estrous cycle and after stimulation of the medial preoptic area?\\n\\nOptions:\\nA) Medial basal hypothalamic LH-RH levels remain constant throughout the rat estrous cycle and do not affect plasma LH changes.\\nB) There is no relationship between medial basal hypothalamic LH-RH levels and plasma LH changes during the rat estrous cycle.\\nC) Increased medial basal hypothalamic LH-RH levels lead to a decrease in plasma LH during the rat estrous cycle.\\nD) Temporal fluctuations in medial basal hypothalamic LH-RH levels correlate with plasma LH changes during the rat estrous cycle and following stimulation of the medial preoptic area.\\n\\nAnswer: D'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:23:41.640830Z",
     "start_time": "2025-05-26T01:22:55.888975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_dataset = DatasetDict({\n",
    "        \"train\": to_transformers_dataset(train_tokenized),\n",
    "        \"eval\":  to_transformers_dataset(eval_tokenized),\n",
    "    }\n",
    ")"
   ],
   "id": "706e95c46cf784cf",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:23:41.654736Z",
     "start_time": "2025-05-26T01:23:41.648731Z"
    }
   },
   "cell_type": "code",
   "source": "len(hf_dataset[\"train\"]), len(hf_dataset[\"eval\"]) # check the length of the datasets",
   "id": "24a22f705f5e807",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16890, 5000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# hf_dataset.push_to_hub(\"Claudia031/maia-pln-2025-training-v2\") # push to hugging face hub",
   "id": "7fc32d7bf3f70eb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:38:23.094323Z",
     "start_time": "2025-05-26T00:38:18.120875Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce8ff781a5df4800b55635f63105f364"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/39.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5ab6bcc769a48898b610576f9e3da40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "eval-00000-of-00001.parquet:   0%|          | 0.00/11.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf52f942eab24827a4197fdae79dd488"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/16890 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e683ccd714f84c42970346d35cef14aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating eval split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa2e46c73e01459c99edf97d6d622351"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2,
   "source": "dataset = load_dataset(\"Claudia031/maia-pln-2025-training-v2\") # claudia's dataset (under our team member account)",
   "id": "14d245f0e6ce531f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:41:59.078565Z",
     "start_time": "2025-05-26T00:41:59.068327Z"
    }
   },
   "cell_type": "code",
   "source": "print(tokenizer.decode(dataset[\"train\"][0][\"input_ids\"], skip_special_tokens=True))",
   "id": "9f0bf2e266cdfab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert AI specializing in multiple-choice questions.\n",
      "Your task is to analyze the provided context, question, and options, then identify the single best answer.\n",
      "Respond with only the capital letter (A, B, C, or D) corresponding to your choice.\n",
      "\n",
      "Context:\n",
      "The rate of action of calcium on the electrical and mechanical responses of the crayfish muscle fibers. The effects of sudden changes in external Ca concentration on the time courses of the changes in size of the action potential and of the associated contraction in a single crayfish muscle fiber were investigated. Procaine-HCl was added to the bathing solution to make the muscle fiber excitable. The concentration of the divalent cations (Ca and Mg) was high enough to keep the threshold potential constant. In Ca-free solution, neither action potential nor contraction was observed. When the external Ca concentration was suddenly increased from 0 to 14 mM, the full sized action potentials were generated within several seconds, but the tensions recovered slowly in an exponential time course with the time constants of 15-40 sec depending on the muscle fiber radius. The tension recovery was further delayed by addition of Dextran to the bathing solution, and it was also slowed at temperatures as low as 4-5 degrees C. When the Ca concentration was changed from 14 mM to 0 mM, the decreased in action potential was slow rather than instantaneous. The delay in tension recovery was attributed to the diffusion time of Ca ions into the TTS, and it was suggested that the Ca entry through the TTS membranes was the first step in the excitation-contraction coupling of the crayfish muscle fibers. The diffusion coefficient of Ca ions inside the TTS was calculated from the recovery time of tension development. It was one order smaller than that in free solution.\n",
      "\n",
      "Question:\n",
      "What did the study reveal about the role of external calcium concentration in the action potential and contraction recovery time of crayfish muscle fibers?\n",
      "\n",
      "Options:\n",
      "A) The study found that increasing external calcium concentration had no effect on the action potential or contraction recovery time in crayfish muscle fibers.\n",
      "B) The study investigated how changes in external calcium concentration affect the action potential and contraction recovery time in crayfish muscle fibers, revealing that calcium entry through TTS membranes is crucial for excitation-contraction coupling.\n",
      "C) The investigation revealed that external calcium concentration only affects the resting potential of crayfish muscle fibers, not the action potential or contraction recovery.\n",
      "D) The research concluded that magnesium ions play a more significant role than calcium in the action potential and contraction recovery of crayfish muscle fibers.\n",
      "\n",
      "Answer: B\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lora fine tune: search for all modules that can be trained\n",
    "\n",
    "We are going to fine tune the modules `['q_proj', 'v_proj', 'down_proj', 'o_proj', 'k_proj', 'up_proj', 'gate_proj']` which\n",
    "are the linear layers in the model\n",
    "\n",
    "In order to prevent overfitting we will use LoRA (Low-Rank Adaptation) to fine tune the model with dropout and weight decay.\n",
    "\n",
    "Dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of the input units to zero during training\n",
    "\n",
    "Other thing used to prevent overfitting is load the best model at the end of training, which is done by setting `load_best_model_at_end=True` in the `TrainingArguments`, in conjunction with metric `eval_loss`."
   ],
   "id": "f541c3236294fe63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:45:08.740305Z",
     "start_time": "2025-05-26T00:45:04.767571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    ")"
   ],
   "id": "2b227ac960892cb7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:45:09.424376Z",
     "start_time": "2025-05-26T00:45:09.412272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = nn.Linear  # Use standard Linear layer\n",
    "    linear_module_names = set()\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            linear_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in linear_module_names:  # Optionally exclude output head\n",
    "        linear_module_names.remove('lm_head')\n",
    "\n",
    "    return list(linear_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "modules"
   ],
   "id": "a692a117bf77cdae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q_proj', 'v_proj', 'down_proj', 'o_proj', 'k_proj', 'up_proj', 'gate_proj']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:46:03.566909Z",
     "start_time": "2025-05-26T00:46:03.560751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset len\n",
    "len(dataset[\"train\"]), len(dataset[\"eval\"])"
   ],
   "id": "f20e412761120e2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16890, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:24:38.144912Z",
     "start_time": "2025-05-26T01:24:38.140207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps_per_epoch = 2000\n",
    "batch_size = 4"
   ],
   "id": "467efb831b683c85",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,  # we have tested that with 16 and 8 but 16 is better for this model\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05, # we have tested that with 0.05 and 0.1 but 0.05 is better for this model\n",
    "    bias=\"lora_only\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    init_lora_weights=True,  # Initialize LoRA weights to zero\n",
    "    use_rslora=False,  # Standard LoRA (more predictable)\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=steps_per_epoch,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=steps_per_epoch,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,      # because lower eval_loss is better\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=steps_per_epoch,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01, # prevent overfitting scheduling a weight decay, which is a regularization technique that helps prevent overfitting by penalizing large weights\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"eval\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "360febaf75422ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer.save_model(\"./outputs/fine-tuning/trainer\")\n",
    "tokenizer.save_pretrained(\"./outputs/fine-tuning/tokenizer\")"
   ],
   "id": "62f4169e24c93f39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
