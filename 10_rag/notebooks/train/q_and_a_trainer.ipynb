{
 "cells": [
  {
   "cell_type": "code",
   "id": "ed6db18fd76b2ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T01:55:31.430445Z",
     "start_time": "2025-05-24T01:55:31.427593Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMultipleChoice\n",
    "\n",
    "from data.q_and_a.train_and_eval import TrainAndEval\n",
    "from data.q_and_a.eval_with_answers import EvalWithAnswers\n",
    "from q_and_a.prompts import prompt\n",
    "from data.q_and_a.prompted import Prompted\n",
    "import torch.optim"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T01:56:38.578581Z",
     "start_time": "2025-05-24T01:56:38.349290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "AutoModelForMultipleChoice.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
   ],
   "id": "ebd87986a3dc4c95",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.llama.configuration_llama.LlamaConfig'> for this kind of AutoModel: AutoModelForMultipleChoice.\nModel type should be one of AlbertConfig, BertConfig, BigBirdConfig, CamembertConfig, CanineConfig, ConvBertConfig, Data2VecTextConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, FlaubertConfig, FNetConfig, FunnelConfig, IBertConfig, LongformerConfig, LukeConfig, MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MraConfig, NezhaConfig, NystromformerConfig, QDQBertConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m login\n\u001B[1;32m      2\u001B[0m login(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhf_gmCHnzBJGRSuhEXbHRAnNpmymBYpwKZVfd\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mAutoModelForMultipleChoice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmeta-llama/Llama-3.2-1B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:574\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    570\u001B[0m         config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget_text_config()\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m    572\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    573\u001B[0m     )\n\u001B[0;32m--> 574\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    577\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: Unrecognized configuration class <class 'transformers.models.llama.configuration_llama.LlamaConfig'> for this kind of AutoModel: AutoModelForMultipleChoice.\nModel type should be one of AlbertConfig, BertConfig, BigBirdConfig, CamembertConfig, CanineConfig, ConvBertConfig, Data2VecTextConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, FlaubertConfig, FNetConfig, FunnelConfig, IBertConfig, LongformerConfig, LukeConfig, MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MraConfig, NezhaConfig, NystromformerConfig, QDQBertConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig."
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "2e887d6c-b795-4e16-91c7-1d42bf0ed466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:33.591260Z",
     "start_time": "2025-05-23T14:00:33.129994Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "Invalid user token.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:409\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 409\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/requests/models.py:1024\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1024\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/hf_api.py:1746\u001B[0m, in \u001B[0;36mHfApi.whoami\u001B[0;34m(self, token)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1746\u001B[0m     \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:482\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001B[39;00m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;66;03m# as well (request id and/or server error message)\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m _format(HfHubHTTPError, \u001B[38;5;28mstr\u001B[39m(e), response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2 (Request ID: Root=1-68307f81-7072b8d117b254682f118749;dd75f24d-98b1-4c89-b11d-13d0ad8b13c1)\n\nInvalid credentials in Authorization header",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_22690/1861983187.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mhuggingface_hub\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlogin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mlogin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"{}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     97\u001B[0m                 )\n\u001B[1;32m     98\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mcustom_message\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m                     \u001B[0mmessage\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\"\\n\\n\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mcustom_message\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m                 \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFutureWarning\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m             args_msg = [\n\u001B[1;32m     34\u001B[0m                 \u001B[0;34mf\"{name}='{arg}'\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34mf\"{name}={arg}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/_login.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(token, add_to_git_credential, new_session, write_permission)\u001B[0m\n\u001B[1;32m    122\u001B[0m                 \u001B[0;34m\"`add_to_git_credential=True` in this function directly or \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m                 \u001B[0;34m\"`--add-to-git-credential` if using via `huggingface-cli` if \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m                 \u001B[0;34m\"you want to set the git credential as well.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m             )\n\u001B[0;32m--> 126\u001B[0;31m         \u001B[0m_login\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_to_git_credential\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0madd_to_git_credential\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    127\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mis_notebook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[0mnotebook_login\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_session\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnew_session\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/_login.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(token, add_to_git_credential)\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    401\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"api_org\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    402\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"You must use your personal account token, not an organization token.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 404\u001B[0;31m     \u001B[0mtoken_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwhoami\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    405\u001B[0m     \u001B[0mpermission\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtoken_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"auth\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"accessToken\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"role\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Token is valid (permission: {permission}).\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    407\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcheck_use_auth_token\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m             \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msmoothly_deprecate_use_auth_token\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhas_token\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhas_token\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/huggingface_hub/hf_api.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, token)\u001B[0m\n\u001B[1;32m   1755\u001B[0m                     \u001B[0;34m\"Note that HF_TOKEN takes precedence over `huggingface-cli login`.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1756\u001B[0m                 )\n\u001B[1;32m   1757\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0meffective_token\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_get_token_from_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1758\u001B[0m                 \u001B[0merror_message\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\" The token stored is invalid. Please run `huggingface-cli login` to update it.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1759\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_message\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1760\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mHTTPError\u001B[0m: Invalid user token."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "d162f20ef30d6267",
   "metadata": {},
   "source": [
    "# First, load the data\n",
    "\n",
    "We are going to load the data used for train or modify our classification task."
   ]
  },
  {
   "cell_type": "code",
   "id": "b421e8d542499a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:47.689765Z",
     "start_time": "2025-05-23T14:00:47.686840Z"
    }
   },
   "source": [
    "class Tokenized(Dataset):\n",
    "    def __init__(self, tokenizer, dataset: Prompted, max_length=2000):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset = dataset\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        text, answer = self.dataset[idx]\n",
    "\n",
    "        result = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",)\n",
    "        labels = torch.tensor(answer, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": result[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": result[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": labels,\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:48.421730Z",
     "start_time": "2025-05-23T14:00:48.047177Z"
    }
   },
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_dataset = TrainAndEval(\"../../data/pubmed_QA_train.json\")\n",
    "test_dataset = TrainAndEval(\"../../data/pubmed_QA_eval.json\")\n",
    "train_with_answers = EvalWithAnswers(train_dataset)\n",
    "test_with_answers = EvalWithAnswers(test_dataset)\n",
    "train_prompted= Prompted(train_with_answers, prompt)\n",
    "test_prompted = Prompted(test_with_answers, prompt)\n",
    "train_tokenized = Tokenized(tokenizer, train_prompted)\n",
    "test_tokenized = Tokenized(tokenizer, test_prompted)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8d0fe24ee7e060bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:48.431076Z",
     "start_time": "2025-05-23T14:00:48.427312Z"
    }
   },
   "source": [
    "len(train_tokenized), len(test_tokenized)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16890, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "80862c4188d6abcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:48.560822Z",
     "start_time": "2025-05-23T14:00:48.557575Z"
    }
   },
   "source": [
    "# per now use a subset\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_tokenized = Subset(train_tokenized, range(0, 2000))\n",
    "test_tokenized = Subset(test_tokenized, range(0, 200))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "42109f869b4cbf7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:50.601815Z",
     "start_time": "2025-05-23T14:00:48.701842Z"
    }
   },
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=4,\n",
    "    load_in_8bit=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "2aa5a9bda5cccd98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:50.617322Z",
     "start_time": "2025-05-23T14:00:50.614147Z"
    }
   },
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"score\" not in name:\n",
    "        print(f\"grad non required on:{name}\")\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        print(f\"requires grad: {name}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad non required on:model.embed_tokens.weight\n",
      "grad non required on:model.layers.0.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.0.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.0.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.0.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.0.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.0.mlp.up_proj.weight\n",
      "grad non required on:model.layers.0.mlp.down_proj.weight\n",
      "grad non required on:model.layers.0.input_layernorm.weight\n",
      "grad non required on:model.layers.0.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.1.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.1.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.1.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.1.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.1.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.1.mlp.up_proj.weight\n",
      "grad non required on:model.layers.1.mlp.down_proj.weight\n",
      "grad non required on:model.layers.1.input_layernorm.weight\n",
      "grad non required on:model.layers.1.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.2.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.2.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.2.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.2.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.2.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.2.mlp.up_proj.weight\n",
      "grad non required on:model.layers.2.mlp.down_proj.weight\n",
      "grad non required on:model.layers.2.input_layernorm.weight\n",
      "grad non required on:model.layers.2.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.3.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.3.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.3.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.3.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.3.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.3.mlp.up_proj.weight\n",
      "grad non required on:model.layers.3.mlp.down_proj.weight\n",
      "grad non required on:model.layers.3.input_layernorm.weight\n",
      "grad non required on:model.layers.3.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.4.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.4.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.4.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.4.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.4.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.4.mlp.up_proj.weight\n",
      "grad non required on:model.layers.4.mlp.down_proj.weight\n",
      "grad non required on:model.layers.4.input_layernorm.weight\n",
      "grad non required on:model.layers.4.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.5.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.5.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.5.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.5.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.5.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.5.mlp.up_proj.weight\n",
      "grad non required on:model.layers.5.mlp.down_proj.weight\n",
      "grad non required on:model.layers.5.input_layernorm.weight\n",
      "grad non required on:model.layers.5.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.6.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.6.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.6.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.6.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.6.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.6.mlp.up_proj.weight\n",
      "grad non required on:model.layers.6.mlp.down_proj.weight\n",
      "grad non required on:model.layers.6.input_layernorm.weight\n",
      "grad non required on:model.layers.6.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.7.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.7.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.7.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.7.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.7.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.7.mlp.up_proj.weight\n",
      "grad non required on:model.layers.7.mlp.down_proj.weight\n",
      "grad non required on:model.layers.7.input_layernorm.weight\n",
      "grad non required on:model.layers.7.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.8.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.8.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.8.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.8.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.8.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.8.mlp.up_proj.weight\n",
      "grad non required on:model.layers.8.mlp.down_proj.weight\n",
      "grad non required on:model.layers.8.input_layernorm.weight\n",
      "grad non required on:model.layers.8.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.9.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.9.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.9.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.9.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.9.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.9.mlp.up_proj.weight\n",
      "grad non required on:model.layers.9.mlp.down_proj.weight\n",
      "grad non required on:model.layers.9.input_layernorm.weight\n",
      "grad non required on:model.layers.9.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.10.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.10.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.10.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.10.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.10.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.10.mlp.up_proj.weight\n",
      "grad non required on:model.layers.10.mlp.down_proj.weight\n",
      "grad non required on:model.layers.10.input_layernorm.weight\n",
      "grad non required on:model.layers.10.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.11.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.11.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.11.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.11.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.11.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.11.mlp.up_proj.weight\n",
      "grad non required on:model.layers.11.mlp.down_proj.weight\n",
      "grad non required on:model.layers.11.input_layernorm.weight\n",
      "grad non required on:model.layers.11.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.12.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.12.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.12.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.12.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.12.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.12.mlp.up_proj.weight\n",
      "grad non required on:model.layers.12.mlp.down_proj.weight\n",
      "grad non required on:model.layers.12.input_layernorm.weight\n",
      "grad non required on:model.layers.12.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.13.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.13.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.13.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.13.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.13.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.13.mlp.up_proj.weight\n",
      "grad non required on:model.layers.13.mlp.down_proj.weight\n",
      "grad non required on:model.layers.13.input_layernorm.weight\n",
      "grad non required on:model.layers.13.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.14.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.14.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.14.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.14.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.14.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.14.mlp.up_proj.weight\n",
      "grad non required on:model.layers.14.mlp.down_proj.weight\n",
      "grad non required on:model.layers.14.input_layernorm.weight\n",
      "grad non required on:model.layers.14.post_attention_layernorm.weight\n",
      "grad non required on:model.layers.15.self_attn.q_proj.weight\n",
      "grad non required on:model.layers.15.self_attn.k_proj.weight\n",
      "grad non required on:model.layers.15.self_attn.v_proj.weight\n",
      "grad non required on:model.layers.15.self_attn.o_proj.weight\n",
      "grad non required on:model.layers.15.mlp.gate_proj.weight\n",
      "grad non required on:model.layers.15.mlp.up_proj.weight\n",
      "grad non required on:model.layers.15.mlp.down_proj.weight\n",
      "grad non required on:model.layers.15.input_layernorm.weight\n",
      "grad non required on:model.layers.15.post_attention_layernorm.weight\n",
      "grad non required on:model.norm.weight\n",
      "requires grad: score.weight\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "cb9ff885cdf1dd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:50.737648Z",
     "start_time": "2025-05-23T14:00:50.675784Z"
    }
   },
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank of LoRA matrices (lower = less memory)\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Depends on model architecture\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    modules_to_save=[\"score\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 860,160 || all params: 1,236,682,752 || trainable%: 0.0696\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e02fc05c8e95d278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:52.319970Z",
     "start_time": "2025-05-23T14:00:50.752383Z"
    }
   },
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22690/3351656164.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 5.65 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 5.39 GiB is allocated by PyTorch, and 63.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 25\u001B[0m\n\u001B[1;32m      3\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[1;32m      4\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./checkpoints\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     eval_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m     fp16\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     18\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     19\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[1;32m     23\u001B[0m )\n\u001B[0;32m---> 25\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/trainer.py:2245\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2243\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   2244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2245\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2246\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2250\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/trainer.py:2560\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2553\u001B[0m context \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2554\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mno_sync, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[1;32m   2555\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_samples) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2556\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m!=\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED\n\u001B[1;32m   2557\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext\n\u001B[1;32m   2558\u001B[0m )\n\u001B[1;32m   2559\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[0;32m-> 2560\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2562\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2563\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2564\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2565\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2566\u001B[0m ):\n\u001B[1;32m   2567\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2568\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/trainer.py:3736\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs, num_items_in_batch)\u001B[0m\n\u001B[1;32m   3733\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3735\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3736\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3738\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[1;32m   3739\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   3740\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3741\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   3742\u001B[0m ):\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/trainer.py:3801\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001B[0m\n\u001B[1;32m   3799\u001B[0m         loss_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_items_in_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_items_in_batch\n\u001B[1;32m   3800\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_kwargs}\n\u001B[0;32m-> 3801\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/accelerate/utils/operations.py:818\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 818\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/accelerate/utils/operations.py:806\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    805\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/amp/autocast_mode.py:44\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/peft/peft_model.py:2352\u001B[0m, in \u001B[0;36mPeftModelForTokenClassification.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m peft_config\u001B[38;5;241m.\u001B[39mpeft_type \u001B[38;5;241m==\u001B[39m PeftType\u001B[38;5;241m.\u001B[39mPOLY:\n\u001B[1;32m   2351\u001B[0m             kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m task_ids\n\u001B[0;32m-> 2352\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2353\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2354\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2355\u001B[0m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2356\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2357\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2358\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2359\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2360\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2361\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2363\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2365\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:193\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_top_level_module\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[1;32m    967\u001B[0m         output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:904\u001B[0m, in \u001B[0;36mLlamaForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states)\u001B[0m\n\u001B[1;32m    883\u001B[0m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(LLAMA_INPUTS_DOCSTRING)\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    895\u001B[0m     output_hidden_states: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    896\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SequenceClassifierOutputWithPast:\n\u001B[1;32m    897\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 904\u001B[0m     transformer_outputs: BaseModelOutputWithPast \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    914\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[1;32m    915\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore(hidden_states)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_top_level_module\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[1;32m    967\u001B[0m         output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:571\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    560\u001B[0m         partial(decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mflash_attn_kwargs),\n\u001B[1;32m    561\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    568\u001B[0m         position_embeddings,\n\u001B[1;32m    569\u001B[0m     )\n\u001B[1;32m    570\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 571\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    575\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    576\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mflash_attn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    583\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:334\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    332\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    333\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_attention_layernorm(hidden_states)\n\u001B[0;32m--> 334\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    337\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (hidden_states,)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:172\u001B[0m, in \u001B[0;36mLlamaMLP.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 172\u001B[0m     down_proj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown_proj(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_fn(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgate_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup_proj(x))\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m down_proj\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:990\u001B[0m, in \u001B[0;36mLinear8bitLt.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m x\u001B[38;5;241m.\u001B[39mdtype:\n\u001B[1;32m    988\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m--> 990\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mbnb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mhas_fp16_weights \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mCB \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    993\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mCB\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:509\u001B[0m, in \u001B[0;36mmatmul\u001B[0;34m(A, B, out, state, threshold, bias)\u001B[0m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m threshold \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m    508\u001B[0m     state\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[0;32m--> 509\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMatMul8bitLt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/autograd/function.py:575\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    574\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    583\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:373\u001B[0m, in \u001B[0;36mMatMul8bitLt.forward\u001B[0;34m(ctx, A, B, out, bias, state)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# Dequantize matmul result\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m bias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;66;03m# we apply the fused bias here\u001B[39;00m\n\u001B[0;32m--> 373\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint8_mm_dequant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout32\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSCA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSCB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(A\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# apply bias separately\u001B[39;00m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;66;03m# TODO: Fused bias for fp32/bf16?\u001B[39;00m\n\u001B[1;32m    376\u001B[0m     output \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mint8_mm_dequant(out32, SCA, state\u001B[38;5;241m.\u001B[39mSCB, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(A\u001B[38;5;241m.\u001B[39mdtype)\u001B[38;5;241m.\u001B[39madd_(bias)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/functional.py:2405\u001B[0m, in \u001B[0;36mint8_mm_dequant\u001B[0;34m(A, row_stats, col_stats, out, bias)\u001B[0m\n\u001B[1;32m   2402\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m bias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16\n\u001B[1;32m   2404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 2405\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat16\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2407\u001B[0m ptrA \u001B[38;5;241m=\u001B[39m get_ptr(A)\n\u001B[1;32m   2408\u001B[0m ptrOut \u001B[38;5;241m=\u001B[39m get_ptr(out)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 5.65 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 5.39 GiB is allocated by PyTorch, and 63.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3208d266f14f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:52.322137188Z",
     "start_time": "2025-05-18T21:33:06.264229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU Name: NVIDIA H100 80GB HBM3\n",
      "Supports FP16: (9, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Supports FP16:\", torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bfee5a3f760cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:52.326318136Z",
     "start_time": "2025-05-18T21:33:06.311901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./last-checkpoint/tokenizer/tokenizer_config.json',\n",
       " './last-checkpoint/tokenizer/special_tokens_map.json',\n",
       " './last-checkpoint/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./last-checkpoint/trainer\")\n",
    "tokenizer.save_pretrained(\"./last-checkpoint/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f218db450583d652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:52.326850040Z",
     "start_time": "2025-05-18T21:33:06.385113Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./last-checkpoint/model\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "e41c6d26d1a1fcf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:01:07.712296Z",
     "start_time": "2025-05-23T14:01:05.579953Z"
    }
   },
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "\n",
    "from data.q_and_a.train_and_eval import TrainAndEval\n",
    "from data.q_and_a.eval_with_answers import EvalWithAnswers\n",
    "\n",
    "from models_.building.llama_tokenizer import  load_tokenizer\n",
    "\n",
    "from data.pubmed.from_json import FromJsonDataset\n",
    "from data.pubmed.contents import ContentsDataset\n",
    "\n",
    "from storage.faiss_ import FaissStorage\n",
    "\n",
    "from rag.tokenization.llama import build_tokenizer_function\n",
    "from rag.quering import build_querier\n",
    "import os\n",
    "from q_and_a.forward import build_enhanced_forwarder\n",
    "from q_and_a.prompts import prompt\n",
    "from q_and_a.picking.from_logits import build_from_logits\n",
    "from q_and_a.eval import evaluate\n",
    "from q_and_a.forward import build_forwarder\n",
    "\n",
    "train = TrainAndEval(\"../../data/pubmed_QA_train.json\")\n",
    "evaluationData = TrainAndEval(\"../../data/pubmed_QA_eval.json\")\n",
    "evaluateWithAnswers = EvalWithAnswers(evaluationData)\n",
    "\n",
    "augmented_data = FromJsonDataset(json_file=\"../../data/pubmed_500K.json\")\n",
    "augmented_data = ContentsDataset(augmented_data)\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "storage = FaissStorage(\n",
    "    dimension=800,\n",
    ")\n",
    "\n",
    "storage.load(\"../../outputs/store/pubmed_500K.index\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9d091af245c43c294a30a2a123b31b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "7c1dd0480019f2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:01:26.564694Z",
     "start_time": "2025-05-23T14:01:25.962681Z"
    }
   },
   "source": [
    "tokenizer_rag = load_tokenizer()\n",
    "tokenizer_fn = build_tokenizer_function(tokenizer_rag)\n",
    "\n",
    "querier = build_querier(storage, augmented_data, tokenizer_fn)\n",
    "storage = FaissStorage(\n",
    "    dimension=800,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "40447f2f-446f-4b8d-9d19-bb2fb1774973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:01:27.238001Z",
     "start_time": "2025-05-23T14:01:27.235930Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ddff1133-aa61-48ba-8f46-185ffbffd031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:01:28.057317Z",
     "start_time": "2025-05-23T14:01:27.740008Z"
    }
   },
   "source": [
    "model.eval()\n",
    "forward = build_forwarder(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    querier,\n",
    "    k_augmentations=1,\n",
    "    prompt_builder=prompt,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "forward_and_get_arg_max = lambda question, options: forward(\n",
    "    question,\n",
    "    options=options,\n",
    ")\n",
    "\n",
    "def pick_from_classifier(out):\n",
    "    return torch.argmax(out.logits[0])\n",
    "\n",
    "accuracy = evaluate(\n",
    "    forward_fn=forward_and_get_arg_max,\n",
    "    picker_fn=pick_from_classifier,\n",
    "    eval_dataset=evaluateWithAnswers,\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 5.65 GiB of which 8.00 MiB is free. Including non-PyTorch memory, this process has 5.62 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 67.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpick_from_classifier\u001B[39m(out):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39margmax(out\u001B[38;5;241m.\u001B[39mlogits[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 19\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforward_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforward_and_get_arg_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpicker_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpick_from_classifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluateWithAnswers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Try/pytorch_training/10_rag/src/q_and_a/eval.py:35\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(forward_fn, picker_fn, eval_dataset, log_each)\u001B[0m\n\u001B[1;32m     32\u001B[0m answer_idx \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Get the model's response\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Pick the best option\u001B[39;00m\n\u001B[1;32m     38\u001B[0m picked_idx \u001B[38;5;241m=\u001B[39m picker_fn(response)\n",
      "Cell \u001B[0;32mIn[15], line 11\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(question, options)\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      2\u001B[0m forward \u001B[38;5;241m=\u001B[39m build_forwarder(\n\u001B[1;32m      3\u001B[0m     model,\n\u001B[1;32m      4\u001B[0m     tokenizer,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m      9\u001B[0m )\n\u001B[0;32m---> 11\u001B[0m forward_and_get_arg_max \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m question, options: \u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpick_from_classifier\u001B[39m(out):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39margmax(out\u001B[38;5;241m.\u001B[39mlogits[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Try/pytorch_training/10_rag/src/q_and_a/forward.py:68\u001B[0m, in \u001B[0;36mbuild_forwarder.<locals>.forward_fn\u001B[0;34m(question, options)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward_fn\u001B[39m(question: \u001B[38;5;28mstr\u001B[39m, options: List[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m---> 68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m        \u001B[49m\u001B[43maugmenter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maugmenter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk_augmentations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk_augmentations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt_builder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt_builder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcausal_llm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_llm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Try/pytorch_training/10_rag/src/q_and_a/forward.py:48\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(llm, tokenizer, augmenter, k_augmentations, prompt_builder, question, options, device, causal_llm)\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m  llm(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresult, do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 48\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mllm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/accelerate/utils/operations.py:818\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 818\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/accelerate/utils/operations.py:806\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    805\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/amp/autocast_mode.py:44\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/peft/peft_model.py:2352\u001B[0m, in \u001B[0;36mPeftModelForTokenClassification.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m peft_config\u001B[38;5;241m.\u001B[39mpeft_type \u001B[38;5;241m==\u001B[39m PeftType\u001B[38;5;241m.\u001B[39mPOLY:\n\u001B[1;32m   2351\u001B[0m             kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m task_ids\n\u001B[0;32m-> 2352\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2353\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2354\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2355\u001B[0m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2356\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2357\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2358\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2359\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2360\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2361\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2363\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2365\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:193\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_top_level_module\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[1;32m    967\u001B[0m         output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:904\u001B[0m, in \u001B[0;36mLlamaForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states)\u001B[0m\n\u001B[1;32m    883\u001B[0m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(LLAMA_INPUTS_DOCSTRING)\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    895\u001B[0m     output_hidden_states: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    896\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SequenceClassifierOutputWithPast:\n\u001B[1;32m    897\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 904\u001B[0m     transformer_outputs: BaseModelOutputWithPast \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    914\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[1;32m    915\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore(hidden_states)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_top_level_module\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[1;32m    967\u001B[0m         output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:571\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    560\u001B[0m         partial(decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mflash_attn_kwargs),\n\u001B[1;32m    561\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    568\u001B[0m         position_embeddings,\n\u001B[1;32m    569\u001B[0m     )\n\u001B[1;32m    570\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 571\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    575\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    576\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mflash_attn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    583\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:334\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    332\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    333\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_attention_layernorm(hidden_states)\n\u001B[0;32m--> 334\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    337\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (hidden_states,)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:172\u001B[0m, in \u001B[0;36mLlamaMLP.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 172\u001B[0m     down_proj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown_proj(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_fn(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgate_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup_proj(x))\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m down_proj\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:990\u001B[0m, in \u001B[0;36mLinear8bitLt.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m x\u001B[38;5;241m.\u001B[39mdtype:\n\u001B[1;32m    988\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m--> 990\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mbnb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mhas_fp16_weights \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mCB \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    993\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mCB\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:509\u001B[0m, in \u001B[0;36mmatmul\u001B[0;34m(A, B, out, state, threshold, bias)\u001B[0m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m threshold \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m    508\u001B[0m     state\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[0;32m--> 509\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMatMul8bitLt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/torch/autograd/function.py:575\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    574\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    583\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:373\u001B[0m, in \u001B[0;36mMatMul8bitLt.forward\u001B[0;34m(ctx, A, B, out, bias, state)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# Dequantize matmul result\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m bias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;66;03m# we apply the fused bias here\u001B[39;00m\n\u001B[0;32m--> 373\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint8_mm_dequant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout32\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSCA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSCB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(A\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# apply bias separately\u001B[39;00m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;66;03m# TODO: Fused bias for fp32/bf16?\u001B[39;00m\n\u001B[1;32m    376\u001B[0m     output \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mint8_mm_dequant(out32, SCA, state\u001B[38;5;241m.\u001B[39mSCB, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(A\u001B[38;5;241m.\u001B[39mdtype)\u001B[38;5;241m.\u001B[39madd_(bias)\n",
      "File \u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/bitsandbytes/functional.py:2405\u001B[0m, in \u001B[0;36mint8_mm_dequant\u001B[0;34m(A, row_stats, col_stats, out, bias)\u001B[0m\n\u001B[1;32m   2402\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m bias\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16\n\u001B[1;32m   2404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 2405\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat16\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2407\u001B[0m ptrA \u001B[38;5;241m=\u001B[39m get_ptr(A)\n\u001B[1;32m   2408\u001B[0m ptrOut \u001B[38;5;241m=\u001B[39m get_ptr(out)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 5.65 GiB of which 8.00 MiB is free. Including non-PyTorch memory, this process has 5.62 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 67.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4656d02-9965-4673-870d-19acefd98d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from q_and_a.predict import predict\n",
    "from data.q_and_a.test_questions import TestQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9190324b-0fb7-49ad-9640-99ba17542c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestQuestions(\"../../data/pubmed_QA_test_questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "816fa818-c0c9-4242-a998-1606160cdc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0.1%\n",
      "Processed 0.2%\n",
      "Processed 0.3%\n",
      "Processed 0.4%\n",
      "Processed 0.5%\n",
      "Processed 0.6%\n",
      "Processed 0.7%\n",
      "Processed 0.8%\n",
      "Processed 0.9%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, tensor(1, device='cuda:0')),\n",
       " (1, tensor(3, device='cuda:0')),\n",
       " (2, tensor(2, device='cuda:0')),\n",
       " (3, tensor(1, device='cuda:0')),\n",
       " (4, tensor(2, device='cuda:0')),\n",
       " (5, tensor(1, device='cuda:0')),\n",
       " (6, tensor(2, device='cuda:0')),\n",
       " (7, tensor(2, device='cuda:0')),\n",
       " (8, tensor(1, device='cuda:0')),\n",
       " (9, tensor(0, device='cuda:0')),\n",
       " (10, tensor(3, device='cuda:0')),\n",
       " (11, tensor(3, device='cuda:0')),\n",
       " (12, tensor(2, device='cuda:0')),\n",
       " (13, tensor(3, device='cuda:0')),\n",
       " (14, tensor(3, device='cuda:0')),\n",
       " (15, tensor(1, device='cuda:0')),\n",
       " (16, tensor(3, device='cuda:0')),\n",
       " (17, tensor(2, device='cuda:0')),\n",
       " (18, tensor(0, device='cuda:0')),\n",
       " (19, tensor(2, device='cuda:0')),\n",
       " (20, tensor(1, device='cuda:0')),\n",
       " (21, tensor(3, device='cuda:0')),\n",
       " (22, tensor(2, device='cuda:0')),\n",
       " (23, tensor(1, device='cuda:0')),\n",
       " (24, tensor(1, device='cuda:0')),\n",
       " (25, tensor(1, device='cuda:0')),\n",
       " (26, tensor(3, device='cuda:0')),\n",
       " (27, tensor(0, device='cuda:0')),\n",
       " (28, tensor(2, device='cuda:0')),\n",
       " (29, tensor(2, device='cuda:0')),\n",
       " (30, tensor(0, device='cuda:0')),\n",
       " (31, tensor(3, device='cuda:0')),\n",
       " (32, tensor(3, device='cuda:0')),\n",
       " (33, tensor(1, device='cuda:0')),\n",
       " (34, tensor(2, device='cuda:0')),\n",
       " (35, tensor(0, device='cuda:0')),\n",
       " (36, tensor(1, device='cuda:0')),\n",
       " (37, tensor(0, device='cuda:0')),\n",
       " (38, tensor(3, device='cuda:0')),\n",
       " (39, tensor(3, device='cuda:0')),\n",
       " (40, tensor(0, device='cuda:0')),\n",
       " (41, tensor(0, device='cuda:0')),\n",
       " (42, tensor(0, device='cuda:0')),\n",
       " (43, tensor(1, device='cuda:0')),\n",
       " (44, tensor(3, device='cuda:0')),\n",
       " (45, tensor(0, device='cuda:0')),\n",
       " (46, tensor(2, device='cuda:0')),\n",
       " (47, tensor(1, device='cuda:0')),\n",
       " (48, tensor(0, device='cuda:0')),\n",
       " (49, tensor(1, device='cuda:0')),\n",
       " (50, tensor(3, device='cuda:0')),\n",
       " (51, tensor(3, device='cuda:0')),\n",
       " (52, tensor(0, device='cuda:0')),\n",
       " (53, tensor(1, device='cuda:0')),\n",
       " (54, tensor(3, device='cuda:0')),\n",
       " (55, tensor(2, device='cuda:0')),\n",
       " (56, tensor(3, device='cuda:0')),\n",
       " (57, tensor(3, device='cuda:0')),\n",
       " (58, tensor(1, device='cuda:0')),\n",
       " (59, tensor(2, device='cuda:0')),\n",
       " (60, tensor(0, device='cuda:0')),\n",
       " (61, tensor(0, device='cuda:0')),\n",
       " (62, tensor(3, device='cuda:0')),\n",
       " (63, tensor(0, device='cuda:0')),\n",
       " (64, tensor(2, device='cuda:0')),\n",
       " (65, tensor(2, device='cuda:0')),\n",
       " (66, tensor(1, device='cuda:0')),\n",
       " (67, tensor(0, device='cuda:0')),\n",
       " (68, tensor(0, device='cuda:0')),\n",
       " (69, tensor(0, device='cuda:0')),\n",
       " (70, tensor(3, device='cuda:0')),\n",
       " (71, tensor(1, device='cuda:0')),\n",
       " (72, tensor(3, device='cuda:0')),\n",
       " (73, tensor(2, device='cuda:0')),\n",
       " (74, tensor(3, device='cuda:0')),\n",
       " (75, tensor(3, device='cuda:0')),\n",
       " (76, tensor(0, device='cuda:0')),\n",
       " (77, tensor(1, device='cuda:0')),\n",
       " (78, tensor(2, device='cuda:0')),\n",
       " (79, tensor(2, device='cuda:0')),\n",
       " (80, tensor(3, device='cuda:0')),\n",
       " (81, tensor(0, device='cuda:0')),\n",
       " (82, tensor(0, device='cuda:0')),\n",
       " (83, tensor(3, device='cuda:0')),\n",
       " (84, tensor(1, device='cuda:0')),\n",
       " (85, tensor(3, device='cuda:0')),\n",
       " (86, tensor(0, device='cuda:0')),\n",
       " (87, tensor(0, device='cuda:0')),\n",
       " (88, tensor(3, device='cuda:0')),\n",
       " (89, tensor(0, device='cuda:0')),\n",
       " (90, tensor(2, device='cuda:0')),\n",
       " (91, tensor(1, device='cuda:0')),\n",
       " (92, tensor(3, device='cuda:0')),\n",
       " (93, tensor(3, device='cuda:0')),\n",
       " (94, tensor(0, device='cuda:0')),\n",
       " (95, tensor(2, device='cuda:0')),\n",
       " (96, tensor(3, device='cuda:0')),\n",
       " (97, tensor(0, device='cuda:0')),\n",
       " (98, tensor(3, device='cuda:0')),\n",
       " (99, tensor(0, device='cuda:0')),\n",
       " (100, tensor(3, device='cuda:0')),\n",
       " (101, tensor(1, device='cuda:0')),\n",
       " (102, tensor(1, device='cuda:0')),\n",
       " (103, tensor(3, device='cuda:0')),\n",
       " (104, tensor(3, device='cuda:0')),\n",
       " (105, tensor(1, device='cuda:0')),\n",
       " (106, tensor(3, device='cuda:0')),\n",
       " (107, tensor(0, device='cuda:0')),\n",
       " (108, tensor(1, device='cuda:0')),\n",
       " (109, tensor(0, device='cuda:0')),\n",
       " (110, tensor(3, device='cuda:0')),\n",
       " (111, tensor(0, device='cuda:0')),\n",
       " (112, tensor(1, device='cuda:0')),\n",
       " (113, tensor(3, device='cuda:0')),\n",
       " (114, tensor(0, device='cuda:0')),\n",
       " (115, tensor(0, device='cuda:0')),\n",
       " (116, tensor(1, device='cuda:0')),\n",
       " (117, tensor(1, device='cuda:0')),\n",
       " (118, tensor(3, device='cuda:0')),\n",
       " (119, tensor(3, device='cuda:0')),\n",
       " (120, tensor(0, device='cuda:0')),\n",
       " (121, tensor(0, device='cuda:0')),\n",
       " (122, tensor(2, device='cuda:0')),\n",
       " (123, tensor(0, device='cuda:0')),\n",
       " (124, tensor(1, device='cuda:0')),\n",
       " (125, tensor(3, device='cuda:0')),\n",
       " (126, tensor(2, device='cuda:0')),\n",
       " (127, tensor(3, device='cuda:0')),\n",
       " (128, tensor(2, device='cuda:0')),\n",
       " (129, tensor(3, device='cuda:0')),\n",
       " (130, tensor(3, device='cuda:0')),\n",
       " (131, tensor(2, device='cuda:0')),\n",
       " (132, tensor(0, device='cuda:0')),\n",
       " (133, tensor(1, device='cuda:0')),\n",
       " (134, tensor(3, device='cuda:0')),\n",
       " (135, tensor(3, device='cuda:0')),\n",
       " (136, tensor(1, device='cuda:0')),\n",
       " (137, tensor(3, device='cuda:0')),\n",
       " (138, tensor(3, device='cuda:0')),\n",
       " (139, tensor(3, device='cuda:0')),\n",
       " (140, tensor(0, device='cuda:0')),\n",
       " (141, tensor(3, device='cuda:0')),\n",
       " (142, tensor(1, device='cuda:0')),\n",
       " (143, tensor(2, device='cuda:0')),\n",
       " (144, tensor(1, device='cuda:0')),\n",
       " (145, tensor(3, device='cuda:0')),\n",
       " (146, tensor(3, device='cuda:0')),\n",
       " (147, tensor(1, device='cuda:0')),\n",
       " (148, tensor(3, device='cuda:0')),\n",
       " (149, tensor(3, device='cuda:0')),\n",
       " (150, tensor(1, device='cuda:0')),\n",
       " (151, tensor(1, device='cuda:0')),\n",
       " (152, tensor(0, device='cuda:0')),\n",
       " (153, tensor(0, device='cuda:0')),\n",
       " (154, tensor(1, device='cuda:0')),\n",
       " (155, tensor(3, device='cuda:0')),\n",
       " (156, tensor(2, device='cuda:0')),\n",
       " (157, tensor(1, device='cuda:0')),\n",
       " (158, tensor(3, device='cuda:0')),\n",
       " (159, tensor(2, device='cuda:0')),\n",
       " (160, tensor(3, device='cuda:0')),\n",
       " (161, tensor(2, device='cuda:0')),\n",
       " (162, tensor(0, device='cuda:0')),\n",
       " (163, tensor(3, device='cuda:0')),\n",
       " (164, tensor(1, device='cuda:0')),\n",
       " (165, tensor(2, device='cuda:0')),\n",
       " (166, tensor(1, device='cuda:0')),\n",
       " (167, tensor(2, device='cuda:0')),\n",
       " (168, tensor(3, device='cuda:0')),\n",
       " (169, tensor(0, device='cuda:0')),\n",
       " (170, tensor(2, device='cuda:0')),\n",
       " (171, tensor(2, device='cuda:0')),\n",
       " (172, tensor(3, device='cuda:0')),\n",
       " (173, tensor(1, device='cuda:0')),\n",
       " (174, tensor(0, device='cuda:0')),\n",
       " (175, tensor(1, device='cuda:0')),\n",
       " (176, tensor(1, device='cuda:0')),\n",
       " (177, tensor(1, device='cuda:0')),\n",
       " (178, tensor(0, device='cuda:0')),\n",
       " (179, tensor(2, device='cuda:0')),\n",
       " (180, tensor(0, device='cuda:0')),\n",
       " (181, tensor(3, device='cuda:0')),\n",
       " (182, tensor(0, device='cuda:0')),\n",
       " (183, tensor(2, device='cuda:0')),\n",
       " (184, tensor(1, device='cuda:0')),\n",
       " (185, tensor(3, device='cuda:0')),\n",
       " (186, tensor(1, device='cuda:0')),\n",
       " (187, tensor(3, device='cuda:0')),\n",
       " (188, tensor(3, device='cuda:0')),\n",
       " (189, tensor(3, device='cuda:0')),\n",
       " (190, tensor(3, device='cuda:0')),\n",
       " (191, tensor(1, device='cuda:0')),\n",
       " (192, tensor(0, device='cuda:0')),\n",
       " (193, tensor(3, device='cuda:0')),\n",
       " (194, tensor(1, device='cuda:0')),\n",
       " (195, tensor(0, device='cuda:0')),\n",
       " (196, tensor(0, device='cuda:0')),\n",
       " (197, tensor(2, device='cuda:0')),\n",
       " (198, tensor(3, device='cuda:0')),\n",
       " (199, tensor(0, device='cuda:0')),\n",
       " (200, tensor(2, device='cuda:0')),\n",
       " (201, tensor(3, device='cuda:0')),\n",
       " (202, tensor(1, device='cuda:0')),\n",
       " (203, tensor(0, device='cuda:0')),\n",
       " (204, tensor(0, device='cuda:0')),\n",
       " (205, tensor(1, device='cuda:0')),\n",
       " (206, tensor(3, device='cuda:0')),\n",
       " (207, tensor(3, device='cuda:0')),\n",
       " (208, tensor(2, device='cuda:0')),\n",
       " (209, tensor(2, device='cuda:0')),\n",
       " (210, tensor(3, device='cuda:0')),\n",
       " (211, tensor(0, device='cuda:0')),\n",
       " (212, tensor(3, device='cuda:0')),\n",
       " (213, tensor(3, device='cuda:0')),\n",
       " (214, tensor(3, device='cuda:0')),\n",
       " (215, tensor(3, device='cuda:0')),\n",
       " (216, tensor(2, device='cuda:0')),\n",
       " (217, tensor(1, device='cuda:0')),\n",
       " (218, tensor(1, device='cuda:0')),\n",
       " (219, tensor(3, device='cuda:0')),\n",
       " (220, tensor(0, device='cuda:0')),\n",
       " (221, tensor(0, device='cuda:0')),\n",
       " (222, tensor(2, device='cuda:0')),\n",
       " (223, tensor(3, device='cuda:0')),\n",
       " (224, tensor(3, device='cuda:0')),\n",
       " (225, tensor(2, device='cuda:0')),\n",
       " (226, tensor(3, device='cuda:0')),\n",
       " (227, tensor(3, device='cuda:0')),\n",
       " (228, tensor(2, device='cuda:0')),\n",
       " (229, tensor(2, device='cuda:0')),\n",
       " (230, tensor(1, device='cuda:0')),\n",
       " (231, tensor(1, device='cuda:0')),\n",
       " (232, tensor(2, device='cuda:0')),\n",
       " (233, tensor(1, device='cuda:0')),\n",
       " (234, tensor(2, device='cuda:0')),\n",
       " (235, tensor(0, device='cuda:0')),\n",
       " (236, tensor(2, device='cuda:0')),\n",
       " (237, tensor(0, device='cuda:0')),\n",
       " (238, tensor(2, device='cuda:0')),\n",
       " (239, tensor(0, device='cuda:0')),\n",
       " (240, tensor(0, device='cuda:0')),\n",
       " (241, tensor(3, device='cuda:0')),\n",
       " (242, tensor(1, device='cuda:0')),\n",
       " (243, tensor(1, device='cuda:0')),\n",
       " (244, tensor(2, device='cuda:0')),\n",
       " (245, tensor(2, device='cuda:0')),\n",
       " (246, tensor(0, device='cuda:0')),\n",
       " (247, tensor(2, device='cuda:0')),\n",
       " (248, tensor(1, device='cuda:0')),\n",
       " (249, tensor(3, device='cuda:0')),\n",
       " (250, tensor(3, device='cuda:0')),\n",
       " (251, tensor(3, device='cuda:0')),\n",
       " (252, tensor(0, device='cuda:0')),\n",
       " (253, tensor(3, device='cuda:0')),\n",
       " (254, tensor(0, device='cuda:0')),\n",
       " (255, tensor(0, device='cuda:0')),\n",
       " (256, tensor(0, device='cuda:0')),\n",
       " (257, tensor(1, device='cuda:0')),\n",
       " (258, tensor(0, device='cuda:0')),\n",
       " (259, tensor(2, device='cuda:0')),\n",
       " (260, tensor(2, device='cuda:0')),\n",
       " (261, tensor(3, device='cuda:0')),\n",
       " (262, tensor(1, device='cuda:0')),\n",
       " (263, tensor(2, device='cuda:0')),\n",
       " (264, tensor(0, device='cuda:0')),\n",
       " (265, tensor(2, device='cuda:0')),\n",
       " (266, tensor(3, device='cuda:0')),\n",
       " (267, tensor(2, device='cuda:0')),\n",
       " (268, tensor(3, device='cuda:0')),\n",
       " (269, tensor(2, device='cuda:0')),\n",
       " (270, tensor(0, device='cuda:0')),\n",
       " (271, tensor(1, device='cuda:0')),\n",
       " (272, tensor(1, device='cuda:0')),\n",
       " (273, tensor(1, device='cuda:0')),\n",
       " (274, tensor(0, device='cuda:0')),\n",
       " (275, tensor(3, device='cuda:0')),\n",
       " (276, tensor(1, device='cuda:0')),\n",
       " (277, tensor(3, device='cuda:0')),\n",
       " (278, tensor(3, device='cuda:0')),\n",
       " (279, tensor(1, device='cuda:0')),\n",
       " (280, tensor(3, device='cuda:0')),\n",
       " (281, tensor(0, device='cuda:0')),\n",
       " (282, tensor(1, device='cuda:0')),\n",
       " (283, tensor(3, device='cuda:0')),\n",
       " (284, tensor(3, device='cuda:0')),\n",
       " (285, tensor(3, device='cuda:0')),\n",
       " (286, tensor(3, device='cuda:0')),\n",
       " (287, tensor(3, device='cuda:0')),\n",
       " (288, tensor(3, device='cuda:0')),\n",
       " (289, tensor(1, device='cuda:0')),\n",
       " (290, tensor(1, device='cuda:0')),\n",
       " (291, tensor(0, device='cuda:0')),\n",
       " (292, tensor(2, device='cuda:0')),\n",
       " (293, tensor(0, device='cuda:0')),\n",
       " (294, tensor(3, device='cuda:0')),\n",
       " (295, tensor(3, device='cuda:0')),\n",
       " (296, tensor(0, device='cuda:0')),\n",
       " (297, tensor(1, device='cuda:0')),\n",
       " (298, tensor(0, device='cuda:0')),\n",
       " (299, tensor(1, device='cuda:0')),\n",
       " (300, tensor(1, device='cuda:0')),\n",
       " (301, tensor(3, device='cuda:0')),\n",
       " (302, tensor(0, device='cuda:0')),\n",
       " (303, tensor(0, device='cuda:0')),\n",
       " (304, tensor(3, device='cuda:0')),\n",
       " (305, tensor(1, device='cuda:0')),\n",
       " (306, tensor(3, device='cuda:0')),\n",
       " (307, tensor(1, device='cuda:0')),\n",
       " (308, tensor(3, device='cuda:0')),\n",
       " (309, tensor(0, device='cuda:0')),\n",
       " (310, tensor(3, device='cuda:0')),\n",
       " (311, tensor(2, device='cuda:0')),\n",
       " (312, tensor(3, device='cuda:0')),\n",
       " (313, tensor(2, device='cuda:0')),\n",
       " (314, tensor(0, device='cuda:0')),\n",
       " (315, tensor(1, device='cuda:0')),\n",
       " (316, tensor(2, device='cuda:0')),\n",
       " (317, tensor(3, device='cuda:0')),\n",
       " (318, tensor(3, device='cuda:0')),\n",
       " (319, tensor(3, device='cuda:0')),\n",
       " (320, tensor(2, device='cuda:0')),\n",
       " (321, tensor(3, device='cuda:0')),\n",
       " (322, tensor(3, device='cuda:0')),\n",
       " (323, tensor(3, device='cuda:0')),\n",
       " (324, tensor(1, device='cuda:0')),\n",
       " (325, tensor(0, device='cuda:0')),\n",
       " (326, tensor(3, device='cuda:0')),\n",
       " (327, tensor(3, device='cuda:0')),\n",
       " (328, tensor(3, device='cuda:0')),\n",
       " (329, tensor(3, device='cuda:0')),\n",
       " (330, tensor(3, device='cuda:0')),\n",
       " (331, tensor(0, device='cuda:0')),\n",
       " (332, tensor(3, device='cuda:0')),\n",
       " (333, tensor(2, device='cuda:0')),\n",
       " (334, tensor(2, device='cuda:0')),\n",
       " (335, tensor(0, device='cuda:0')),\n",
       " (336, tensor(3, device='cuda:0')),\n",
       " (337, tensor(1, device='cuda:0')),\n",
       " (338, tensor(3, device='cuda:0')),\n",
       " (339, tensor(0, device='cuda:0')),\n",
       " (340, tensor(0, device='cuda:0')),\n",
       " (341, tensor(1, device='cuda:0')),\n",
       " (342, tensor(2, device='cuda:0')),\n",
       " (343, tensor(1, device='cuda:0')),\n",
       " (344, tensor(0, device='cuda:0')),\n",
       " (345, tensor(1, device='cuda:0')),\n",
       " (346, tensor(3, device='cuda:0')),\n",
       " (347, tensor(2, device='cuda:0')),\n",
       " (348, tensor(2, device='cuda:0')),\n",
       " (349, tensor(3, device='cuda:0')),\n",
       " (350, tensor(2, device='cuda:0')),\n",
       " (351, tensor(1, device='cuda:0')),\n",
       " (352, tensor(3, device='cuda:0')),\n",
       " (353, tensor(1, device='cuda:0')),\n",
       " (354, tensor(1, device='cuda:0')),\n",
       " (355, tensor(3, device='cuda:0')),\n",
       " (356, tensor(2, device='cuda:0')),\n",
       " (357, tensor(2, device='cuda:0')),\n",
       " (358, tensor(2, device='cuda:0')),\n",
       " (359, tensor(3, device='cuda:0')),\n",
       " (360, tensor(3, device='cuda:0')),\n",
       " (361, tensor(0, device='cuda:0')),\n",
       " (362, tensor(0, device='cuda:0')),\n",
       " (363, tensor(3, device='cuda:0')),\n",
       " (364, tensor(3, device='cuda:0')),\n",
       " (365, tensor(2, device='cuda:0')),\n",
       " (366, tensor(3, device='cuda:0')),\n",
       " (367, tensor(3, device='cuda:0')),\n",
       " (368, tensor(3, device='cuda:0')),\n",
       " (369, tensor(0, device='cuda:0')),\n",
       " (370, tensor(1, device='cuda:0')),\n",
       " (371, tensor(0, device='cuda:0')),\n",
       " (372, tensor(2, device='cuda:0')),\n",
       " (373, tensor(1, device='cuda:0')),\n",
       " (374, tensor(0, device='cuda:0')),\n",
       " (375, tensor(0, device='cuda:0')),\n",
       " (376, tensor(3, device='cuda:0')),\n",
       " (377, tensor(1, device='cuda:0')),\n",
       " (378, tensor(3, device='cuda:0')),\n",
       " (379, tensor(0, device='cuda:0')),\n",
       " (380, tensor(1, device='cuda:0')),\n",
       " (381, tensor(3, device='cuda:0')),\n",
       " (382, tensor(3, device='cuda:0')),\n",
       " (383, tensor(2, device='cuda:0')),\n",
       " (384, tensor(3, device='cuda:0')),\n",
       " (385, tensor(0, device='cuda:0')),\n",
       " (386, tensor(0, device='cuda:0')),\n",
       " (387, tensor(1, device='cuda:0')),\n",
       " (388, tensor(0, device='cuda:0')),\n",
       " (389, tensor(0, device='cuda:0')),\n",
       " (390, tensor(3, device='cuda:0')),\n",
       " (391, tensor(3, device='cuda:0')),\n",
       " (392, tensor(2, device='cuda:0')),\n",
       " (393, tensor(0, device='cuda:0')),\n",
       " (394, tensor(3, device='cuda:0')),\n",
       " (395, tensor(0, device='cuda:0')),\n",
       " (396, tensor(0, device='cuda:0')),\n",
       " (397, tensor(1, device='cuda:0')),\n",
       " (398, tensor(3, device='cuda:0')),\n",
       " (399, tensor(1, device='cuda:0')),\n",
       " (400, tensor(2, device='cuda:0')),\n",
       " (401, tensor(0, device='cuda:0')),\n",
       " (402, tensor(2, device='cuda:0')),\n",
       " (403, tensor(0, device='cuda:0')),\n",
       " (404, tensor(3, device='cuda:0')),\n",
       " (405, tensor(1, device='cuda:0')),\n",
       " (406, tensor(1, device='cuda:0')),\n",
       " (407, tensor(0, device='cuda:0')),\n",
       " (408, tensor(3, device='cuda:0')),\n",
       " (409, tensor(1, device='cuda:0')),\n",
       " (410, tensor(1, device='cuda:0')),\n",
       " (411, tensor(2, device='cuda:0')),\n",
       " (412, tensor(3, device='cuda:0')),\n",
       " (413, tensor(1, device='cuda:0')),\n",
       " (414, tensor(3, device='cuda:0')),\n",
       " (415, tensor(2, device='cuda:0')),\n",
       " (416, tensor(3, device='cuda:0')),\n",
       " (417, tensor(3, device='cuda:0')),\n",
       " (418, tensor(3, device='cuda:0')),\n",
       " (419, tensor(3, device='cuda:0')),\n",
       " (420, tensor(1, device='cuda:0')),\n",
       " (421, tensor(3, device='cuda:0')),\n",
       " (422, tensor(3, device='cuda:0')),\n",
       " (423, tensor(0, device='cuda:0')),\n",
       " (424, tensor(0, device='cuda:0')),\n",
       " (425, tensor(1, device='cuda:0')),\n",
       " (426, tensor(1, device='cuda:0')),\n",
       " (427, tensor(3, device='cuda:0')),\n",
       " (428, tensor(3, device='cuda:0')),\n",
       " (429, tensor(2, device='cuda:0')),\n",
       " (430, tensor(1, device='cuda:0')),\n",
       " (431, tensor(3, device='cuda:0')),\n",
       " (432, tensor(2, device='cuda:0')),\n",
       " (433, tensor(0, device='cuda:0')),\n",
       " (434, tensor(3, device='cuda:0')),\n",
       " (435, tensor(3, device='cuda:0')),\n",
       " (436, tensor(3, device='cuda:0')),\n",
       " (437, tensor(0, device='cuda:0')),\n",
       " (438, tensor(2, device='cuda:0')),\n",
       " (439, tensor(2, device='cuda:0')),\n",
       " (440, tensor(1, device='cuda:0')),\n",
       " (441, tensor(1, device='cuda:0')),\n",
       " (442, tensor(3, device='cuda:0')),\n",
       " (443, tensor(3, device='cuda:0')),\n",
       " (444, tensor(1, device='cuda:0')),\n",
       " (445, tensor(0, device='cuda:0')),\n",
       " (446, tensor(2, device='cuda:0')),\n",
       " (447, tensor(2, device='cuda:0')),\n",
       " (448, tensor(3, device='cuda:0')),\n",
       " (449, tensor(0, device='cuda:0')),\n",
       " (450, tensor(3, device='cuda:0')),\n",
       " (451, tensor(0, device='cuda:0')),\n",
       " (452, tensor(2, device='cuda:0')),\n",
       " (453, tensor(1, device='cuda:0')),\n",
       " (454, tensor(0, device='cuda:0')),\n",
       " (455, tensor(1, device='cuda:0')),\n",
       " (456, tensor(2, device='cuda:0')),\n",
       " (457, tensor(3, device='cuda:0')),\n",
       " (458, tensor(3, device='cuda:0')),\n",
       " (459, tensor(2, device='cuda:0')),\n",
       " (460, tensor(2, device='cuda:0')),\n",
       " (461, tensor(3, device='cuda:0')),\n",
       " (462, tensor(1, device='cuda:0')),\n",
       " (463, tensor(1, device='cuda:0')),\n",
       " (464, tensor(3, device='cuda:0')),\n",
       " (465, tensor(3, device='cuda:0')),\n",
       " (466, tensor(3, device='cuda:0')),\n",
       " (467, tensor(3, device='cuda:0')),\n",
       " (468, tensor(1, device='cuda:0')),\n",
       " (469, tensor(1, device='cuda:0')),\n",
       " (470, tensor(3, device='cuda:0')),\n",
       " (471, tensor(3, device='cuda:0')),\n",
       " (472, tensor(2, device='cuda:0')),\n",
       " (473, tensor(0, device='cuda:0')),\n",
       " (474, tensor(3, device='cuda:0')),\n",
       " (475, tensor(1, device='cuda:0')),\n",
       " (476, tensor(2, device='cuda:0')),\n",
       " (477, tensor(3, device='cuda:0')),\n",
       " (478, tensor(3, device='cuda:0')),\n",
       " (479, tensor(3, device='cuda:0')),\n",
       " (480, tensor(3, device='cuda:0')),\n",
       " (481, tensor(3, device='cuda:0')),\n",
       " (482, tensor(3, device='cuda:0')),\n",
       " (483, tensor(3, device='cuda:0')),\n",
       " (484, tensor(3, device='cuda:0')),\n",
       " (485, tensor(0, device='cuda:0')),\n",
       " (486, tensor(2, device='cuda:0')),\n",
       " (487, tensor(1, device='cuda:0')),\n",
       " (488, tensor(1, device='cuda:0')),\n",
       " (489, tensor(0, device='cuda:0')),\n",
       " (490, tensor(2, device='cuda:0')),\n",
       " (491, tensor(3, device='cuda:0')),\n",
       " (492, tensor(3, device='cuda:0')),\n",
       " (493, tensor(1, device='cuda:0')),\n",
       " (494, tensor(0, device='cuda:0')),\n",
       " (495, tensor(1, device='cuda:0')),\n",
       " (496, tensor(3, device='cuda:0')),\n",
       " (497, tensor(0, device='cuda:0')),\n",
       " (498, tensor(1, device='cuda:0')),\n",
       " (499, tensor(3, device='cuda:0')),\n",
       " (500, tensor(1, device='cuda:0')),\n",
       " (501, tensor(2, device='cuda:0')),\n",
       " (502, tensor(1, device='cuda:0')),\n",
       " (503, tensor(3, device='cuda:0')),\n",
       " (504, tensor(0, device='cuda:0')),\n",
       " (505, tensor(2, device='cuda:0')),\n",
       " (506, tensor(0, device='cuda:0')),\n",
       " (507, tensor(2, device='cuda:0')),\n",
       " (508, tensor(2, device='cuda:0')),\n",
       " (509, tensor(2, device='cuda:0')),\n",
       " (510, tensor(2, device='cuda:0')),\n",
       " (511, tensor(3, device='cuda:0')),\n",
       " (512, tensor(3, device='cuda:0')),\n",
       " (513, tensor(1, device='cuda:0')),\n",
       " (514, tensor(0, device='cuda:0')),\n",
       " (515, tensor(3, device='cuda:0')),\n",
       " (516, tensor(3, device='cuda:0')),\n",
       " (517, tensor(1, device='cuda:0')),\n",
       " (518, tensor(3, device='cuda:0')),\n",
       " (519, tensor(1, device='cuda:0')),\n",
       " (520, tensor(0, device='cuda:0')),\n",
       " (521, tensor(1, device='cuda:0')),\n",
       " (522, tensor(3, device='cuda:0')),\n",
       " (523, tensor(3, device='cuda:0')),\n",
       " (524, tensor(3, device='cuda:0')),\n",
       " (525, tensor(1, device='cuda:0')),\n",
       " (526, tensor(1, device='cuda:0')),\n",
       " (527, tensor(0, device='cuda:0')),\n",
       " (528, tensor(0, device='cuda:0')),\n",
       " (529, tensor(2, device='cuda:0')),\n",
       " (530, tensor(3, device='cuda:0')),\n",
       " (531, tensor(1, device='cuda:0')),\n",
       " (532, tensor(2, device='cuda:0')),\n",
       " (533, tensor(0, device='cuda:0')),\n",
       " (534, tensor(3, device='cuda:0')),\n",
       " (535, tensor(1, device='cuda:0')),\n",
       " (536, tensor(3, device='cuda:0')),\n",
       " (537, tensor(3, device='cuda:0')),\n",
       " (538, tensor(0, device='cuda:0')),\n",
       " (539, tensor(2, device='cuda:0')),\n",
       " (540, tensor(3, device='cuda:0')),\n",
       " (541, tensor(1, device='cuda:0')),\n",
       " (542, tensor(3, device='cuda:0')),\n",
       " (543, tensor(0, device='cuda:0')),\n",
       " (544, tensor(3, device='cuda:0')),\n",
       " (545, tensor(1, device='cuda:0')),\n",
       " (546, tensor(2, device='cuda:0')),\n",
       " (547, tensor(2, device='cuda:0')),\n",
       " (548, tensor(0, device='cuda:0')),\n",
       " (549, tensor(2, device='cuda:0')),\n",
       " (550, tensor(0, device='cuda:0')),\n",
       " (551, tensor(2, device='cuda:0')),\n",
       " (552, tensor(3, device='cuda:0')),\n",
       " (553, tensor(3, device='cuda:0')),\n",
       " (554, tensor(3, device='cuda:0')),\n",
       " (555, tensor(0, device='cuda:0')),\n",
       " (556, tensor(1, device='cuda:0')),\n",
       " (557, tensor(3, device='cuda:0')),\n",
       " (558, tensor(3, device='cuda:0')),\n",
       " (559, tensor(1, device='cuda:0')),\n",
       " (560, tensor(2, device='cuda:0')),\n",
       " (561, tensor(0, device='cuda:0')),\n",
       " (562, tensor(3, device='cuda:0')),\n",
       " (563, tensor(0, device='cuda:0')),\n",
       " (564, tensor(0, device='cuda:0')),\n",
       " (565, tensor(1, device='cuda:0')),\n",
       " (566, tensor(3, device='cuda:0')),\n",
       " (567, tensor(1, device='cuda:0')),\n",
       " (568, tensor(3, device='cuda:0')),\n",
       " (569, tensor(1, device='cuda:0')),\n",
       " (570, tensor(1, device='cuda:0')),\n",
       " (571, tensor(3, device='cuda:0')),\n",
       " (572, tensor(3, device='cuda:0')),\n",
       " (573, tensor(2, device='cuda:0')),\n",
       " (574, tensor(3, device='cuda:0')),\n",
       " (575, tensor(2, device='cuda:0')),\n",
       " (576, tensor(2, device='cuda:0')),\n",
       " (577, tensor(3, device='cuda:0')),\n",
       " (578, tensor(0, device='cuda:0')),\n",
       " (579, tensor(2, device='cuda:0')),\n",
       " (580, tensor(3, device='cuda:0')),\n",
       " (581, tensor(0, device='cuda:0')),\n",
       " (582, tensor(0, device='cuda:0')),\n",
       " (583, tensor(3, device='cuda:0')),\n",
       " (584, tensor(3, device='cuda:0')),\n",
       " (585, tensor(0, device='cuda:0')),\n",
       " (586, tensor(1, device='cuda:0')),\n",
       " (587, tensor(3, device='cuda:0')),\n",
       " (588, tensor(1, device='cuda:0')),\n",
       " (589, tensor(3, device='cuda:0')),\n",
       " (590, tensor(3, device='cuda:0')),\n",
       " (591, tensor(0, device='cuda:0')),\n",
       " (592, tensor(3, device='cuda:0')),\n",
       " (593, tensor(0, device='cuda:0')),\n",
       " (594, tensor(1, device='cuda:0')),\n",
       " (595, tensor(3, device='cuda:0')),\n",
       " (596, tensor(1, device='cuda:0')),\n",
       " (597, tensor(3, device='cuda:0')),\n",
       " (598, tensor(1, device='cuda:0')),\n",
       " (599, tensor(1, device='cuda:0')),\n",
       " (600, tensor(0, device='cuda:0')),\n",
       " (601, tensor(3, device='cuda:0')),\n",
       " (602, tensor(3, device='cuda:0')),\n",
       " (603, tensor(0, device='cuda:0')),\n",
       " (604, tensor(3, device='cuda:0')),\n",
       " (605, tensor(3, device='cuda:0')),\n",
       " (606, tensor(2, device='cuda:0')),\n",
       " (607, tensor(1, device='cuda:0')),\n",
       " (608, tensor(3, device='cuda:0')),\n",
       " (609, tensor(3, device='cuda:0')),\n",
       " (610, tensor(2, device='cuda:0')),\n",
       " (611, tensor(0, device='cuda:0')),\n",
       " (612, tensor(2, device='cuda:0')),\n",
       " (613, tensor(1, device='cuda:0')),\n",
       " (614, tensor(2, device='cuda:0')),\n",
       " (615, tensor(0, device='cuda:0')),\n",
       " (616, tensor(3, device='cuda:0')),\n",
       " (617, tensor(3, device='cuda:0')),\n",
       " (618, tensor(1, device='cuda:0')),\n",
       " (619, tensor(0, device='cuda:0')),\n",
       " (620, tensor(3, device='cuda:0')),\n",
       " (621, tensor(3, device='cuda:0')),\n",
       " (622, tensor(2, device='cuda:0')),\n",
       " (623, tensor(3, device='cuda:0')),\n",
       " (624, tensor(1, device='cuda:0')),\n",
       " (625, tensor(2, device='cuda:0')),\n",
       " (626, tensor(0, device='cuda:0')),\n",
       " (627, tensor(2, device='cuda:0')),\n",
       " (628, tensor(2, device='cuda:0')),\n",
       " (629, tensor(2, device='cuda:0')),\n",
       " (630, tensor(0, device='cuda:0')),\n",
       " (631, tensor(3, device='cuda:0')),\n",
       " (632, tensor(2, device='cuda:0')),\n",
       " (633, tensor(2, device='cuda:0')),\n",
       " (634, tensor(0, device='cuda:0')),\n",
       " (635, tensor(3, device='cuda:0')),\n",
       " (636, tensor(1, device='cuda:0')),\n",
       " (637, tensor(0, device='cuda:0')),\n",
       " (638, tensor(0, device='cuda:0')),\n",
       " (639, tensor(3, device='cuda:0')),\n",
       " (640, tensor(3, device='cuda:0')),\n",
       " (641, tensor(1, device='cuda:0')),\n",
       " (642, tensor(1, device='cuda:0')),\n",
       " (643, tensor(1, device='cuda:0')),\n",
       " (644, tensor(3, device='cuda:0')),\n",
       " (645, tensor(0, device='cuda:0')),\n",
       " (646, tensor(0, device='cuda:0')),\n",
       " (647, tensor(3, device='cuda:0')),\n",
       " (648, tensor(0, device='cuda:0')),\n",
       " (649, tensor(3, device='cuda:0')),\n",
       " (650, tensor(2, device='cuda:0')),\n",
       " (651, tensor(2, device='cuda:0')),\n",
       " (652, tensor(3, device='cuda:0')),\n",
       " (653, tensor(1, device='cuda:0')),\n",
       " (654, tensor(3, device='cuda:0')),\n",
       " (655, tensor(3, device='cuda:0')),\n",
       " (656, tensor(3, device='cuda:0')),\n",
       " (657, tensor(3, device='cuda:0')),\n",
       " (658, tensor(3, device='cuda:0')),\n",
       " (659, tensor(0, device='cuda:0')),\n",
       " (660, tensor(1, device='cuda:0')),\n",
       " (661, tensor(2, device='cuda:0')),\n",
       " (662, tensor(2, device='cuda:0')),\n",
       " (663, tensor(0, device='cuda:0')),\n",
       " (664, tensor(1, device='cuda:0')),\n",
       " (665, tensor(3, device='cuda:0')),\n",
       " (666, tensor(2, device='cuda:0')),\n",
       " (667, tensor(0, device='cuda:0')),\n",
       " (668, tensor(0, device='cuda:0')),\n",
       " (669, tensor(2, device='cuda:0')),\n",
       " (670, tensor(0, device='cuda:0')),\n",
       " (671, tensor(2, device='cuda:0')),\n",
       " (672, tensor(3, device='cuda:0')),\n",
       " (673, tensor(3, device='cuda:0')),\n",
       " (674, tensor(1, device='cuda:0')),\n",
       " (675, tensor(0, device='cuda:0')),\n",
       " (676, tensor(3, device='cuda:0')),\n",
       " (677, tensor(2, device='cuda:0')),\n",
       " (678, tensor(0, device='cuda:0')),\n",
       " (679, tensor(2, device='cuda:0')),\n",
       " (680, tensor(0, device='cuda:0')),\n",
       " (681, tensor(2, device='cuda:0')),\n",
       " (682, tensor(2, device='cuda:0')),\n",
       " (683, tensor(2, device='cuda:0')),\n",
       " (684, tensor(1, device='cuda:0')),\n",
       " (685, tensor(2, device='cuda:0')),\n",
       " (686, tensor(3, device='cuda:0')),\n",
       " (687, tensor(0, device='cuda:0')),\n",
       " (688, tensor(1, device='cuda:0')),\n",
       " (689, tensor(1, device='cuda:0')),\n",
       " (690, tensor(2, device='cuda:0')),\n",
       " (691, tensor(1, device='cuda:0')),\n",
       " (692, tensor(3, device='cuda:0')),\n",
       " (693, tensor(1, device='cuda:0')),\n",
       " (694, tensor(2, device='cuda:0')),\n",
       " (695, tensor(2, device='cuda:0')),\n",
       " (696, tensor(1, device='cuda:0')),\n",
       " (697, tensor(0, device='cuda:0')),\n",
       " (698, tensor(0, device='cuda:0')),\n",
       " (699, tensor(3, device='cuda:0')),\n",
       " (700, tensor(0, device='cuda:0')),\n",
       " (701, tensor(3, device='cuda:0')),\n",
       " (702, tensor(2, device='cuda:0')),\n",
       " (703, tensor(0, device='cuda:0')),\n",
       " (704, tensor(2, device='cuda:0')),\n",
       " (705, tensor(0, device='cuda:0')),\n",
       " (706, tensor(3, device='cuda:0')),\n",
       " (707, tensor(2, device='cuda:0')),\n",
       " (708, tensor(3, device='cuda:0')),\n",
       " (709, tensor(0, device='cuda:0')),\n",
       " (710, tensor(2, device='cuda:0')),\n",
       " (711, tensor(1, device='cuda:0')),\n",
       " (712, tensor(3, device='cuda:0')),\n",
       " (713, tensor(2, device='cuda:0')),\n",
       " (714, tensor(2, device='cuda:0')),\n",
       " (715, tensor(3, device='cuda:0')),\n",
       " (716, tensor(3, device='cuda:0')),\n",
       " (717, tensor(3, device='cuda:0')),\n",
       " (718, tensor(3, device='cuda:0')),\n",
       " (719, tensor(1, device='cuda:0')),\n",
       " (720, tensor(0, device='cuda:0')),\n",
       " (721, tensor(0, device='cuda:0')),\n",
       " (722, tensor(0, device='cuda:0')),\n",
       " (723, tensor(0, device='cuda:0')),\n",
       " (724, tensor(0, device='cuda:0')),\n",
       " (725, tensor(3, device='cuda:0')),\n",
       " (726, tensor(2, device='cuda:0')),\n",
       " (727, tensor(1, device='cuda:0')),\n",
       " (728, tensor(1, device='cuda:0')),\n",
       " (729, tensor(3, device='cuda:0')),\n",
       " (730, tensor(1, device='cuda:0')),\n",
       " (731, tensor(1, device='cuda:0')),\n",
       " (732, tensor(0, device='cuda:0')),\n",
       " (733, tensor(1, device='cuda:0')),\n",
       " (734, tensor(0, device='cuda:0')),\n",
       " (735, tensor(2, device='cuda:0')),\n",
       " (736, tensor(3, device='cuda:0')),\n",
       " (737, tensor(0, device='cuda:0')),\n",
       " (738, tensor(0, device='cuda:0')),\n",
       " (739, tensor(3, device='cuda:0')),\n",
       " (740, tensor(0, device='cuda:0')),\n",
       " (741, tensor(1, device='cuda:0')),\n",
       " (742, tensor(0, device='cuda:0')),\n",
       " (743, tensor(3, device='cuda:0')),\n",
       " (744, tensor(1, device='cuda:0')),\n",
       " (745, tensor(3, device='cuda:0')),\n",
       " (746, tensor(2, device='cuda:0')),\n",
       " (747, tensor(1, device='cuda:0')),\n",
       " (748, tensor(3, device='cuda:0')),\n",
       " (749, tensor(3, device='cuda:0')),\n",
       " (750, tensor(3, device='cuda:0')),\n",
       " (751, tensor(3, device='cuda:0')),\n",
       " (752, tensor(0, device='cuda:0')),\n",
       " (753, tensor(1, device='cuda:0')),\n",
       " (754, tensor(2, device='cuda:0')),\n",
       " (755, tensor(1, device='cuda:0')),\n",
       " (756, tensor(2, device='cuda:0')),\n",
       " (757, tensor(1, device='cuda:0')),\n",
       " (758, tensor(0, device='cuda:0')),\n",
       " (759, tensor(2, device='cuda:0')),\n",
       " (760, tensor(0, device='cuda:0')),\n",
       " (761, tensor(1, device='cuda:0')),\n",
       " (762, tensor(3, device='cuda:0')),\n",
       " (763, tensor(0, device='cuda:0')),\n",
       " (764, tensor(2, device='cuda:0')),\n",
       " (765, tensor(0, device='cuda:0')),\n",
       " (766, tensor(2, device='cuda:0')),\n",
       " (767, tensor(3, device='cuda:0')),\n",
       " (768, tensor(2, device='cuda:0')),\n",
       " (769, tensor(3, device='cuda:0')),\n",
       " (770, tensor(0, device='cuda:0')),\n",
       " (771, tensor(0, device='cuda:0')),\n",
       " (772, tensor(2, device='cuda:0')),\n",
       " (773, tensor(1, device='cuda:0')),\n",
       " (774, tensor(1, device='cuda:0')),\n",
       " (775, tensor(3, device='cuda:0')),\n",
       " (776, tensor(0, device='cuda:0')),\n",
       " (777, tensor(2, device='cuda:0')),\n",
       " (778, tensor(1, device='cuda:0')),\n",
       " (779, tensor(1, device='cuda:0')),\n",
       " (780, tensor(1, device='cuda:0')),\n",
       " (781, tensor(1, device='cuda:0')),\n",
       " (782, tensor(2, device='cuda:0')),\n",
       " (783, tensor(2, device='cuda:0')),\n",
       " (784, tensor(0, device='cuda:0')),\n",
       " (785, tensor(1, device='cuda:0')),\n",
       " (786, tensor(1, device='cuda:0')),\n",
       " (787, tensor(2, device='cuda:0')),\n",
       " (788, tensor(2, device='cuda:0')),\n",
       " (789, tensor(3, device='cuda:0')),\n",
       " (790, tensor(2, device='cuda:0')),\n",
       " (791, tensor(0, device='cuda:0')),\n",
       " (792, tensor(1, device='cuda:0')),\n",
       " (793, tensor(2, device='cuda:0')),\n",
       " (794, tensor(0, device='cuda:0')),\n",
       " (795, tensor(3, device='cuda:0')),\n",
       " (796, tensor(2, device='cuda:0')),\n",
       " (797, tensor(0, device='cuda:0')),\n",
       " (798, tensor(3, device='cuda:0')),\n",
       " (799, tensor(3, device='cuda:0')),\n",
       " (800, tensor(2, device='cuda:0')),\n",
       " (801, tensor(3, device='cuda:0')),\n",
       " (802, tensor(0, device='cuda:0')),\n",
       " (803, tensor(3, device='cuda:0')),\n",
       " (804, tensor(2, device='cuda:0')),\n",
       " (805, tensor(0, device='cuda:0')),\n",
       " (806, tensor(3, device='cuda:0')),\n",
       " (807, tensor(1, device='cuda:0')),\n",
       " (808, tensor(0, device='cuda:0')),\n",
       " (809, tensor(3, device='cuda:0')),\n",
       " (810, tensor(0, device='cuda:0')),\n",
       " (811, tensor(1, device='cuda:0')),\n",
       " (812, tensor(1, device='cuda:0')),\n",
       " (813, tensor(1, device='cuda:0')),\n",
       " (814, tensor(3, device='cuda:0')),\n",
       " (815, tensor(1, device='cuda:0')),\n",
       " (816, tensor(0, device='cuda:0')),\n",
       " (817, tensor(3, device='cuda:0')),\n",
       " (818, tensor(1, device='cuda:0')),\n",
       " (819, tensor(2, device='cuda:0')),\n",
       " (820, tensor(3, device='cuda:0')),\n",
       " (821, tensor(1, device='cuda:0')),\n",
       " (822, tensor(0, device='cuda:0')),\n",
       " (823, tensor(2, device='cuda:0')),\n",
       " (824, tensor(0, device='cuda:0')),\n",
       " (825, tensor(1, device='cuda:0')),\n",
       " (826, tensor(1, device='cuda:0')),\n",
       " (827, tensor(3, device='cuda:0')),\n",
       " (828, tensor(3, device='cuda:0')),\n",
       " (829, tensor(1, device='cuda:0')),\n",
       " (830, tensor(1, device='cuda:0')),\n",
       " (831, tensor(1, device='cuda:0')),\n",
       " (832, tensor(2, device='cuda:0')),\n",
       " (833, tensor(0, device='cuda:0')),\n",
       " (834, tensor(1, device='cuda:0')),\n",
       " (835, tensor(3, device='cuda:0')),\n",
       " (836, tensor(0, device='cuda:0')),\n",
       " (837, tensor(3, device='cuda:0')),\n",
       " (838, tensor(0, device='cuda:0')),\n",
       " (839, tensor(3, device='cuda:0')),\n",
       " (840, tensor(1, device='cuda:0')),\n",
       " (841, tensor(1, device='cuda:0')),\n",
       " (842, tensor(3, device='cuda:0')),\n",
       " (843, tensor(1, device='cuda:0')),\n",
       " (844, tensor(3, device='cuda:0')),\n",
       " (845, tensor(2, device='cuda:0')),\n",
       " (846, tensor(1, device='cuda:0')),\n",
       " (847, tensor(2, device='cuda:0')),\n",
       " (848, tensor(1, device='cuda:0')),\n",
       " (849, tensor(3, device='cuda:0')),\n",
       " (850, tensor(1, device='cuda:0')),\n",
       " (851, tensor(3, device='cuda:0')),\n",
       " (852, tensor(0, device='cuda:0')),\n",
       " (853, tensor(3, device='cuda:0')),\n",
       " (854, tensor(2, device='cuda:0')),\n",
       " (855, tensor(2, device='cuda:0')),\n",
       " (856, tensor(2, device='cuda:0')),\n",
       " (857, tensor(3, device='cuda:0')),\n",
       " (858, tensor(3, device='cuda:0')),\n",
       " (859, tensor(0, device='cuda:0')),\n",
       " (860, tensor(3, device='cuda:0')),\n",
       " (861, tensor(0, device='cuda:0')),\n",
       " (862, tensor(3, device='cuda:0')),\n",
       " (863, tensor(1, device='cuda:0')),\n",
       " (864, tensor(0, device='cuda:0')),\n",
       " (865, tensor(3, device='cuda:0')),\n",
       " (866, tensor(3, device='cuda:0')),\n",
       " (867, tensor(1, device='cuda:0')),\n",
       " (868, tensor(1, device='cuda:0')),\n",
       " (869, tensor(1, device='cuda:0')),\n",
       " (870, tensor(0, device='cuda:0')),\n",
       " (871, tensor(3, device='cuda:0')),\n",
       " (872, tensor(2, device='cuda:0')),\n",
       " (873, tensor(3, device='cuda:0')),\n",
       " (874, tensor(3, device='cuda:0')),\n",
       " (875, tensor(1, device='cuda:0')),\n",
       " (876, tensor(1, device='cuda:0')),\n",
       " (877, tensor(1, device='cuda:0')),\n",
       " (878, tensor(0, device='cuda:0')),\n",
       " (879, tensor(1, device='cuda:0')),\n",
       " (880, tensor(0, device='cuda:0')),\n",
       " (881, tensor(2, device='cuda:0')),\n",
       " (882, tensor(0, device='cuda:0')),\n",
       " (883, tensor(3, device='cuda:0')),\n",
       " (884, tensor(2, device='cuda:0')),\n",
       " (885, tensor(0, device='cuda:0')),\n",
       " (886, tensor(0, device='cuda:0')),\n",
       " (887, tensor(2, device='cuda:0')),\n",
       " (888, tensor(3, device='cuda:0')),\n",
       " (889, tensor(2, device='cuda:0')),\n",
       " (890, tensor(2, device='cuda:0')),\n",
       " (891, tensor(2, device='cuda:0')),\n",
       " (892, tensor(3, device='cuda:0')),\n",
       " (893, tensor(0, device='cuda:0')),\n",
       " (894, tensor(1, device='cuda:0')),\n",
       " (895, tensor(3, device='cuda:0')),\n",
       " (896, tensor(2, device='cuda:0')),\n",
       " (897, tensor(3, device='cuda:0')),\n",
       " (898, tensor(3, device='cuda:0')),\n",
       " (899, tensor(2, device='cuda:0')),\n",
       " (900, tensor(3, device='cuda:0')),\n",
       " (901, tensor(2, device='cuda:0')),\n",
       " (902, tensor(2, device='cuda:0')),\n",
       " (903, tensor(0, device='cuda:0')),\n",
       " (904, tensor(1, device='cuda:0')),\n",
       " (905, tensor(1, device='cuda:0')),\n",
       " (906, tensor(0, device='cuda:0')),\n",
       " (907, tensor(0, device='cuda:0')),\n",
       " (908, tensor(2, device='cuda:0')),\n",
       " (909, tensor(0, device='cuda:0')),\n",
       " (910, tensor(2, device='cuda:0')),\n",
       " (911, tensor(3, device='cuda:0')),\n",
       " (912, tensor(0, device='cuda:0')),\n",
       " (913, tensor(3, device='cuda:0')),\n",
       " (914, tensor(3, device='cuda:0')),\n",
       " (915, tensor(1, device='cuda:0')),\n",
       " (916, tensor(3, device='cuda:0')),\n",
       " (917, tensor(1, device='cuda:0')),\n",
       " (918, tensor(1, device='cuda:0')),\n",
       " (919, tensor(0, device='cuda:0')),\n",
       " (920, tensor(1, device='cuda:0')),\n",
       " (921, tensor(3, device='cuda:0')),\n",
       " (922, tensor(1, device='cuda:0')),\n",
       " (923, tensor(3, device='cuda:0')),\n",
       " (924, tensor(1, device='cuda:0')),\n",
       " (925, tensor(0, device='cuda:0')),\n",
       " (926, tensor(2, device='cuda:0')),\n",
       " (927, tensor(3, device='cuda:0')),\n",
       " (928, tensor(3, device='cuda:0')),\n",
       " (929, tensor(3, device='cuda:0')),\n",
       " (930, tensor(0, device='cuda:0')),\n",
       " (931, tensor(3, device='cuda:0')),\n",
       " (932, tensor(2, device='cuda:0')),\n",
       " (933, tensor(1, device='cuda:0')),\n",
       " (934, tensor(0, device='cuda:0')),\n",
       " (935, tensor(0, device='cuda:0')),\n",
       " (936, tensor(3, device='cuda:0')),\n",
       " (937, tensor(1, device='cuda:0')),\n",
       " (938, tensor(1, device='cuda:0')),\n",
       " (939, tensor(3, device='cuda:0')),\n",
       " (940, tensor(2, device='cuda:0')),\n",
       " (941, tensor(1, device='cuda:0')),\n",
       " (942, tensor(3, device='cuda:0')),\n",
       " (943, tensor(0, device='cuda:0')),\n",
       " (944, tensor(3, device='cuda:0')),\n",
       " (945, tensor(2, device='cuda:0')),\n",
       " (946, tensor(2, device='cuda:0')),\n",
       " (947, tensor(2, device='cuda:0')),\n",
       " (948, tensor(2, device='cuda:0')),\n",
       " (949, tensor(0, device='cuda:0')),\n",
       " (950, tensor(2, device='cuda:0')),\n",
       " (951, tensor(3, device='cuda:0')),\n",
       " (952, tensor(1, device='cuda:0')),\n",
       " (953, tensor(1, device='cuda:0')),\n",
       " (954, tensor(3, device='cuda:0')),\n",
       " (955, tensor(1, device='cuda:0')),\n",
       " (956, tensor(1, device='cuda:0')),\n",
       " (957, tensor(1, device='cuda:0')),\n",
       " (958, tensor(2, device='cuda:0')),\n",
       " (959, tensor(3, device='cuda:0')),\n",
       " (960, tensor(2, device='cuda:0')),\n",
       " (961, tensor(0, device='cuda:0')),\n",
       " (962, tensor(1, device='cuda:0')),\n",
       " (963, tensor(3, device='cuda:0')),\n",
       " (964, tensor(2, device='cuda:0')),\n",
       " (965, tensor(3, device='cuda:0')),\n",
       " (966, tensor(3, device='cuda:0')),\n",
       " (967, tensor(0, device='cuda:0')),\n",
       " (968, tensor(2, device='cuda:0')),\n",
       " (969, tensor(3, device='cuda:0')),\n",
       " (970, tensor(2, device='cuda:0')),\n",
       " (971, tensor(2, device='cuda:0')),\n",
       " (972, tensor(3, device='cuda:0')),\n",
       " (973, tensor(1, device='cuda:0')),\n",
       " (974, tensor(0, device='cuda:0')),\n",
       " (975, tensor(1, device='cuda:0')),\n",
       " (976, tensor(2, device='cuda:0')),\n",
       " (977, tensor(3, device='cuda:0')),\n",
       " (978, tensor(3, device='cuda:0')),\n",
       " (979, tensor(1, device='cuda:0')),\n",
       " (980, tensor(1, device='cuda:0')),\n",
       " (981, tensor(1, device='cuda:0')),\n",
       " (982, tensor(2, device='cuda:0')),\n",
       " (983, tensor(2, device='cuda:0')),\n",
       " (984, tensor(3, device='cuda:0')),\n",
       " (985, tensor(1, device='cuda:0')),\n",
       " (986, tensor(1, device='cuda:0')),\n",
       " (987, tensor(2, device='cuda:0')),\n",
       " (988, tensor(0, device='cuda:0')),\n",
       " (989, tensor(1, device='cuda:0')),\n",
       " (990, tensor(2, device='cuda:0')),\n",
       " (991, tensor(3, device='cuda:0')),\n",
       " (992, tensor(2, device='cuda:0')),\n",
       " (993, tensor(3, device='cuda:0')),\n",
       " (994, tensor(3, device='cuda:0')),\n",
       " (995, tensor(2, device='cuda:0')),\n",
       " (996, tensor(0, device='cuda:0')),\n",
       " (997, tensor(0, device='cuda:0')),\n",
       " (998, tensor(3, device='cuda:0')),\n",
       " (999, tensor(1, device='cuda:0'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = predict(\n",
    "    forward_fn=forward_and_get_arg_max,\n",
    "    picker_fn=pick_from_classifier,\n",
    "    eval_dataset=test_data,\n",
    ")\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43aeaf51-0577-4430-aff8-6249e0093416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94d048aa-3455-4ccd-aafe-9fb879b26752",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_with_ids = []\n",
    "\n",
    "for i in range(len(responses)):\n",
    "    responses_with_ids.append((test_data[i][\"id\"], responses[i][1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86e3b418-073f-48ce-a579-b845ae631f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(responses_with_ids, columns=[\"ID\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95c17786-a3e1-47b9-b097-37ad7aa1f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  answer\n",
       "0   26       1\n",
       "1   29       3\n",
       "2   37       2\n",
       "3   70       1\n",
       "4  109       2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6fa9f6-9278-4111-8950-b9d93b90aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a0ff0-258c-445a-a8ac-660028db86ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
