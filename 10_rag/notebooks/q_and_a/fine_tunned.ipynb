{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T22:08:54.008749Z",
     "start_time": "2025-05-18T22:08:51.765207Z"
    }
   },
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from data.q_and_a.train_and_eval import TrainAndEval\n",
    "from data.q_and_a.eval_with_answers import EvalWithAnswers\n",
    "\n",
    "from models_.building.llama_tokenizer import  load_tokenizer\n",
    "\n",
    "from data.pubmed.from_json import FromJsonDataset\n",
    "from data.pubmed.contents import ContentsDataset\n",
    "\n",
    "from storage.faiss_ import FaissStorage\n",
    "\n",
    "from rag.tokenization.llama import build_tokenizer_function\n",
    "from rag.quering import build_querier\n",
    "import os\n",
    "from q_and_a.forward import build_enhanced_forwarder\n",
    "from q_and_a.prompts import prompt\n",
    "from q_and_a.picking.from_logits import build_from_logits\n",
    "from q_and_a.eval import evaluate\n",
    "from q_and_a.forward import build_forwarder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:08:57.702054Z",
     "start_time": "2025-05-18T22:08:54.012825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = TrainAndEval(\"../../data/pubmed_QA_train.json\")\n",
    "evaluationData = TrainAndEval(\"../../data/pubmed_QA_eval.json\")\n",
    "evaluateWithAnswers = EvalWithAnswers(evaluationData)\n",
    "\n",
    "augmented_data = FromJsonDataset(json_file=\"../../data/pubmed_500K.json\")\n",
    "augmented_data = ContentsDataset(augmented_data)"
   ],
   "id": "a3212d14b7781948",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:08:59.256991Z",
     "start_time": "2025-05-18T22:08:57.833844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "storage = FaissStorage(\n",
    "    dimension=800,\n",
    ")\n",
    "\n",
    "storage.load(\"../../outputs/store/pubmed_500K.index\")\n",
    "\n",
    "tokenizer = load_tokenizer()\n",
    "tokenizer_fn = build_tokenizer_function(tokenizer)\n",
    "\n",
    "querier = build_querier(storage, augmented_data, tokenizer_fn)\n",
    "storage = FaissStorage(\n",
    "    dimension=800,\n",
    ")"
   ],
   "id": "d384e32c451cee93",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:11:38.320074Z",
     "start_time": "2025-05-18T22:11:38.317085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint_path = Path(\"/home/ubuntu/pytorch_training/10_rag/notebooks/train/checkpoints/checkpoint-500\")"
   ],
   "id": "52983b50e10a8956",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:11:41.685375Z",
     "start_time": "2025-05-18T22:11:39.424892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path,\n",
    "    load_in_8bit=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    local_files_only=True,\n",
    "    num_labels=4,\n",
    ")\n",
    "\n",
    "model"
   ],
   "id": "ed944743ef4d1401",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear8bitLt(\n",
       "            (base_layer): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): lora.Linear8bitLt(\n",
       "            (base_layer): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:11:42.046222Z",
     "start_time": "2025-05-18T22:11:42.037606Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval()",
   "id": "abef1b2cec60361f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear8bitLt(\n",
       "            (base_layer): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): lora.Linear8bitLt(\n",
       "            (base_layer): Linear8bitLt(in_features=2048, out_features=512, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:12:01.994820Z",
     "start_time": "2025-05-18T22:12:01.990613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "forward = build_forwarder(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    querier,\n",
    "    k_augmentations=1,\n",
    "    prompt_builder=prompt,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "forward_and_get_arg_max = lambda question, options: forward(\n",
    "    question,\n",
    "    options=options,\n",
    ")"
   ],
   "id": "b4531c4e9e2c37b0",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:12:02.352377Z",
     "start_time": "2025-05-18T22:12:02.348272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pick_from_classifier(out):\n",
    "    return torch.argmax(out.logits[0])"
   ],
   "id": "11b8750ad1864c04",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:14:57.593530Z",
     "start_time": "2025-05-18T22:12:02.704886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = evaluate(\n",
    "    forward_fn=forward_and_get_arg_max,\n",
    "    picker_fn=pick_from_classifier,\n",
    "    eval_dataset=evaluateWithAnswers,\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "id": "25e1eb7cf17b6b61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right answer: 2, picked: 0\n",
      "Accuracy at 0: 0.00\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 1, picked: 1\n",
      "Right answer: 0, picked: 1\n",
      "Right answer: 1, picked: 1\n",
      "Right answer: 0, picked: 1\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 2, picked: 1\n",
      "Right answer: 2, picked: 1\n",
      "Right answer: 1, picked: 0\n",
      "Right answer: 0, picked: 0\n",
      "Accuracy at 100: 0.21\n",
      "Right answer: 0, picked: 1\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 1, picked: 0\n",
      "Right answer: 1, picked: 0\n",
      "Right answer: 2, picked: 0\n",
      "Right answer: 2, picked: 1\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 2, picked: 0\n",
      "Right answer: 2, picked: 0\n",
      "Accuracy at 200: 0.19\n",
      "Right answer: 0, picked: 1\n",
      "Right answer: 0, picked: 1\n",
      "Right answer: 2, picked: 0\n",
      "Right answer: 2, picked: 0\n",
      "Right answer: 2, picked: 1\n",
      "Right answer: 0, picked: 0\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 3, picked: 1\n",
      "Right answer: 0, picked: 0\n",
      "Right answer: 3, picked: 0\n",
      "Accuracy at 300: 0.18\n",
      "Right answer: 2, picked: 1\n",
      "Right answer: 1, picked: 1\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 3, picked: 0\n",
      "Right answer: 2, picked: 0\n",
      "Right answer: 1, picked: 1\n",
      "Right answer: 2, picked: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_29311/2388363799.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m accuracy = evaluate(\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mforward_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforward_and_get_arg_max\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mpicker_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpick_from_classifier\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0meval_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevaluateWithAnswers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pytorch_training/10_rag/src/q_and_a/eval.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(forward_fn, picker_fn, eval_dataset, log_each)\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[0moptions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"options\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0manswer_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"answer_idx\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0;31m# Get the model's response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0;31m# Pick the best option\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0mpicked_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpicker_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_29311/2574746734.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(question, options)\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m forward_and_get_arg_max = lambda question, options: forward(\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0mquestion\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0moptions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m )\n",
      "\u001B[0;32m~/pytorch_training/10_rag/src/q_and_a/forward.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(question, options)\u001B[0m\n\u001B[1;32m     67\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m         return forward(\n\u001B[0m\u001B[1;32m     69\u001B[0m             \u001B[0mllm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0mtokenizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m             \u001B[0maugmenter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maugmenter\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pytorch_training/10_rag/src/q_and_a/forward.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(llm, tokenizer, augmenter, k_augmentations, prompt_builder, question, options, device, causal_llm)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0mReturns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mthe\u001B[0m \u001B[0mresponse\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mlanguage\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \"\"\"\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maugmenter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk_augmentations\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m     \u001B[0;31m# Generate the prompt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0mprompt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprompt_builder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitems\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pytorch_training/10_rag/src/rag/quering.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(query, k)\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mquerier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mList\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mperform_query\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/pytorch_training/10_rag/src/rag/quering.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(storage, original_dataset, tokenizer_fn, query, k)\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0mquery\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m ) -> (List, List):\n\u001B[1;32m     37\u001B[0m     \u001B[0mquery_vector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0mdistances\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstorage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_vector\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mindices\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pytorch_training/10_rag/src/storage/faiss_.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, key, k)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;31m# For demonstration purposes, we'll return the first vector in the index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mntotal\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mdistances\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdimension\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'float32'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdistances\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/faiss/__init__.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, x, k, D, I)\u001B[0m\n\u001B[1;32m    318\u001B[0m             \u001B[0mI\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    319\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    320\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 322\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msearch_c\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mD\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mI\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    323\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mD\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/faiss39/lib/python3.9/site-packages/faiss/swigfaiss.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, n, x, k, distances, labels)\u001B[0m\n\u001B[1;32m   2145\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msearch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistances\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2146\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_swigfaiss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIndexFlat_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistances\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1405d5d75cf1a98a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cb7243f4a6d85c26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c3a89377ec09aa28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
