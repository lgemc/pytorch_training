{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:10.431540Z",
     "start_time": "2025-05-11T02:04:07.836916Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from data.prompt_dataset import PromptedEhvoy\n",
    "from data.ehovy_race import EhovyRaceDataset\n",
    "\n",
    "from model.llama_3_2_tokenizer import Llama32Tokenizer\n",
    "from model.llama_3_2 import Llama32\n",
    "from model.options_picker import OptionsPicker"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmanrique/miniconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:13.420081Z",
     "start_time": "2025-05-11T02:04:10.436418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = EhovyRaceDataset(variation=\"high\", split=\"train\", max_article_size=800)\n",
    "data_prompted = PromptedEhvoy(data)"
   ],
   "id": "92814172ea3333b1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:13.571684Z",
     "start_time": "2025-05-11T02:04:13.563208Z"
    }
   },
   "cell_type": "code",
   "source": "data_prompted[0]",
   "id": "9dd08334cc459944",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Context: The air hostess   was in a small kitchen at the back of the plane, preparing the plates for lunch, when a little old lady came and spoke to her, \"Could you please tell me,\" she asked, \"where is the ladies\\' lavatory   in the plane?\"\\n\"Yes, madam,\" said the air hostess and smiled. \"It is right at the other end of the plane---at the front.\"\\nThe little lady went too far. She walked all the way to the front of the plane, opened the door in front of her, and saw the captain of the plane and the other officers. They were all busy with their work and did not see her. She went out again, shut the door and returned to the air hostess.\\n\"Oh, didn\\'t you find it, madam?\" the girl asked her. \"Yes, I did,\" said the little lady. \"But there are four men in the ladies\\' lavatory watching television.\"\\n\\nQuestion: The story happened  _  .\\n\\nOptions:\\nA) in the evening\\nB) in the afternoon\\nC) in the morning\\nD) at midnight\\n\\nAnswer:',\n",
       " 'C')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.382034Z",
     "start_time": "2025-05-11T02:04:13.615141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = Llama32Tokenizer(model_name)\n",
    "model = Llama32(model_name, do_sample=False)\n",
    "options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "options_picker = OptionsPicker(model, tokenizer, options=options, device=\"cuda\")"
   ],
   "id": "5c8b7e8187cc012e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 21:04:16.155159: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-10 21:04:16.174761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746929056.195458   39574 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746929056.202007   39574 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746929056.220802   39574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746929056.220826   39574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746929056.220828   39574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746929056.220830   39574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-10 21:04:16.226519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.400230Z",
     "start_time": "2025-05-11T02:04:19.393382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = data_prompted[0]\n",
    "x"
   ],
   "id": "f15f772ca96c3d0d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context: The air hostess   was in a small kitchen at the back of the plane, preparing the plates for lunch, when a little old lady came and spoke to her, \"Could you please tell me,\" she asked, \"where is the ladies\\' lavatory   in the plane?\"\\n\"Yes, madam,\" said the air hostess and smiled. \"It is right at the other end of the plane---at the front.\"\\nThe little lady went too far. She walked all the way to the front of the plane, opened the door in front of her, and saw the captain of the plane and the other officers. They were all busy with their work and did not see her. She went out again, shut the door and returned to the air hostess.\\n\"Oh, didn\\'t you find it, madam?\" the girl asked her. \"Yes, I did,\" said the little lady. \"But there are four men in the ladies\\' lavatory watching television.\"\\n\\nQuestion: The story happened  _  .\\n\\nOptions:\\nA) in the evening\\nB) in the afternoon\\nC) in the morning\\nD) at midnight\\n\\nAnswer:'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.449747Z",
     "start_time": "2025-05-11T02:04:19.443640Z"
    }
   },
   "cell_type": "code",
   "source": "x_tokenized = tokenizer(x, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)",
   "id": "b0f039b046fee03b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.895243Z",
     "start_time": "2025-05-11T02:04:19.493230Z"
    }
   },
   "cell_type": "code",
   "source": "out = options_picker(x_tokenized[\"input_ids\"], x_tokenized[\"attention_mask\"])",
   "id": "281c0e0c125d5b08",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.939312Z",
     "start_time": "2025-05-11T02:04:19.934709Z"
    }
   },
   "cell_type": "code",
   "source": "print(out)",
   "id": "625dc5452e262fbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9605e-08, 1.1921e-07, 3.5763e-06, 1.4901e-06])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:19.993351Z",
     "start_time": "2025-05-11T02:04:19.986392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = options[torch.argmax(out)]\n",
    "answer"
   ],
   "id": "526d2b11d1b48139",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:04:20.040727Z",
     "start_time": "2025-05-11T02:04:20.037367Z"
    }
   },
   "cell_type": "code",
   "source": "# Let's see how the model performs on the first 100 examples",
   "id": "3c7a8b90ce2e8a69",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:07:14.775818Z",
     "start_time": "2025-05-11T02:07:05.580583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct_predictions = 0\n",
    "validation_length = len(data_prompted)\n",
    "\n",
    "for i in range(validation_length):\n",
    "    x, y = data_prompted[i]\n",
    "    x = x.replace(\"\\n\\nAnswer:\", \"\\n\\nAfter analyze that, the option i choose between (A, B, C or D) is \")\n",
    "    x = f\"\"\"\n",
    "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
    "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
    "     {x}\"\"\"\n",
    "    x_tokenized = tokenizer(x, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    out = options_picker(x_tokenized[\"input_ids\"], x_tokenized[\"attention_mask\"])\n",
    "    answer = options[torch.argmax(out)]\n",
    "    if answer == y:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(out)\n",
    "        print(x)\n",
    "        print(answer, y)\n",
    "        print(f\"Processed {i} examples, current accuracy: {correct_predictions / (i + 1):.2f}\")\n",
    "\n",
    "accuracy = correct_predictions / validation_length\n",
    "accuracy"
   ],
   "id": "ea717fb9295dbb26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9605e-08, 5.9605e-08, 2.1458e-06, 1.0729e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: The air hostess   was in a small kitchen at the back of the plane, preparing the plates for lunch, when a little old lady came and spoke to her, \"Could you please tell me,\" she asked, \"where is the ladies' lavatory   in the plane?\"\n",
      "\"Yes, madam,\" said the air hostess and smiled. \"It is right at the other end of the plane---at the front.\"\n",
      "The little lady went too far. She walked all the way to the front of the plane, opened the door in front of her, and saw the captain of the plane and the other officers. They were all busy with their work and did not see her. She went out again, shut the door and returned to the air hostess.\n",
      "\"Oh, didn't you find it, madam?\" the girl asked her. \"Yes, I did,\" said the little lady. \"But there are four men in the ladies' lavatory watching television.\"\n",
      "\n",
      "Question: The story happened  _  .\n",
      "\n",
      "Options:\n",
      "A) in the evening\n",
      "B) in the afternoon\n",
      "C) in the morning\n",
      "D) at midnight\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C C\n",
      "Processed 0 examples, current accuracy: 1.00\n",
      "tensor([5.9605e-08, 5.9605e-08, 2.5034e-06, 1.6093e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Read the following directions on a bottle of medicine:\n",
      "    \"Take two tablets with water, followed by one tablet every eight hours, as required, For maximum night-time and early morning relief, take two tablets at bed - time, Do not take more than six tablets in twenty-four hours. \n",
      "    For children six to twelve years old, give half the amount for a grownup. For children under six years old, ask for your doctor's advice.\n",
      "    Reduce the amount if nervousness,  _ , or sleeplessness occurs,\"\n",
      "\n",
      "Question: Obviously the medicine   _   .\n",
      "\n",
      "Options:\n",
      "A) may be dangerous to small children.\n",
      "B) cannot be taken by children under twelve years old.\n",
      "C) may be taken by children but not by grown-ups.\n",
      "D) may be taken by grown-ups but not by children.\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C A\n",
      "Processed 10 examples, current accuracy: 0.27\n",
      "tensor([5.9605e-08, 5.9605e-08, 4.1723e-06, 8.3447e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Do you need friends? I'm sure your answer is \"Yes,of course. Everybody does! \" You need friends when you play and when you work. If you have friends, you will feel happy. If you have no friends. you will feel lonely  . \n",
      "Do you know how to make friends? There is only one good way--You make friends by being friendly. \n",
      "A friendly person is interested in other people. He is always helpful If you want to make friends with a new classmate, you can talk with him, tell him about the other classmates in your class and try your best to be helpful to him.\n",
      "\n",
      "Question: A friendly person is   _   other people.\n",
      "\n",
      "Options:\n",
      "A) interested in\n",
      "B) worried about\n",
      "C) surprised at\n",
      "D) like them\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C A\n",
      "Processed 20 examples, current accuracy: 0.38\n",
      "tensor([0.0000e+00, 0.0000e+00, 2.0266e-06, 5.9605e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Once there was a poor farmer and his farm belonged to  a rich man. One day he brought a basket of apples to the rich man's house. On the doorsteps, he met two monkeys dressed like children. They jumped onto the basket to eat the apples and threw some on the ground. The farmer politely took off his hat and asked the monkeys to get off. They obeyed  and the farmer went into the house. He asked to see the rich man. A servant took him to the room where the rich man was sitting.\n",
      "\"I have brought you the basket of apples you asked for,\" he said.\n",
      "\"But why have you brought a half-empty basket?\" the rich man asked.\n",
      "\"I met your children outside, and they stole  some of the apples.\"\n",
      "\n",
      "Question: The monkeys left the basket because\n",
      "\n",
      "Options:\n",
      "A) they had thrown apples on the ground\n",
      "B) the farmer had politely asked them to get off\n",
      "C) they were afraid of the hat\n",
      "D) the farmer was angry wit h them\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C D\n",
      "Processed 30 examples, current accuracy: 0.29\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.0133e-06, 5.3644e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: The following notice is posted in the bus station.\n",
      "Time Table:\n",
      "*Buses leave the Railway Station, New York City, from7:00 a.m. and every half-hour thereafter, until 11:30 p.m. (7 days a week)\n",
      "*Buses leave Brennan Station 20 minutes before and after every hour from 6:20 a.m. to 11:40 p.m. (7 days a week)\n",
      "*Evening rush hours (5:00 p.m. to 7:00 p.m.); Buses leave the Railway Station, New York City every 15 minutes.(Monday--Friday)\n",
      "*Holidays Buses leave every hour on the hour, each direction.(Trip time:30minutes each way)\n",
      "*All tickets must be bought at Window 12, the Railway Station, New York City, or at the Brennan Station Window BEFORE boarding buses.\n",
      "\n",
      "Question: Where should passengers buy their tickets?\n",
      "\n",
      "Options:\n",
      "A) From the bus driver.\n",
      "B) On the bus after getting on it.\n",
      "C) From the conductor.\n",
      "D) At the station before boarding.\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C D\n",
      "Processed 40 examples, current accuracy: 0.27\n",
      "tensor([0.0000e+00, 5.9605e-08, 1.8477e-06, 6.5565e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Bet Winner\n",
      "MILLBURN, New Jersey-- An 11-year-old boy, he gave up television for a year in a bet with his mother, says he will use some of the money to buy himself an astronaut's suit. The bet ended at 9:01 on Monday morning, but Benjamin waited until his mother, Roslyn, handed him five 100-dollar bills in front of a gathering of newspapermen in the afternoon before switching on the TV. During the past year, he has filled his time reading and his grades have improved from ''satisfactory\" to ''very good.\"\n",
      "CHINA DAILY, Wednesday, March 9, 2011  ( 94 words )\n",
      "\n",
      "Question: Why did the mother hand the bills to the boy?\n",
      "\n",
      "Options:\n",
      "A) Because his grades had improved\n",
      "B) Because he had won some money\n",
      "C) Because he wanted to buy an astronaut's suit\n",
      "D) Because she had given him her promise\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C D\n",
      "Processed 50 examples, current accuracy: 0.25\n",
      "tensor([5.9605e-08, 5.9605e-08, 3.9339e-06, 1.1921e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: London, the capital of England, is political, economic  and commercial  centre. It stands on the Thames, extending for nearly thirty miles from north to south and for nearly thirty miles from east to west.\n",
      "London is divided into many administrative  units. Greater London, the largest unit, cover 1,605 square miles. The heart of this unit is the City of London. It is surrounded by a ring of 12 boroughs  called Inner London or Central London, covering 303 square miles, and itself, is again surrounded by a greater ring of 20 boroughs called Outer London with an area of 1,279 square miles. Thus, Greater London is made up of the City and 32 boroughs.\n",
      "\n",
      "Question: From this article, we can see that London   _  .\n",
      "\n",
      "Options:\n",
      "A) is made up of the City, the Central London and Outer London.\n",
      "B) is made up of Inner London and Outer London\n",
      "C) includes the City, 32 boroughs and some other units.\n",
      "D) is smaller than Greater London in area.\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C C\n",
      "Processed 60 examples, current accuracy: 0.28\n",
      "tensor([5.9605e-08, 5.9605e-08, 1.2279e-05, 1.2517e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Central Sports Centre. City Road.\n",
      "All Stars vs Rockets, Saturday 8: 30 p.m. $12\n",
      "Northerners vs Tigers, Sunday noon $14\n",
      "BUSHWALKING  :\n",
      "Meet at Wanda Station, Saturday 9:00 a.m. sharp for 3-hour walk to Canary Mountains. $7, ph 341-5432 Meet at Westley Station, Sunday 9:00 a.m. sharp for a full day walk to Wombak Valley. $5, ph 341-8643. Bring your own lunch.\n",
      "FOOTBALL:\n",
      "St Martins Sports Centre\n",
      "St Martins vs Doonsberg, Saturday 2:00 p.m. $8\n",
      "Eastside Central vs Light Hill, Sunday 2:00 p.m. $8\n",
      "Neill Park Recreation Centre\n",
      "Neill Park vs Robinson, Saturday 2:00 p.m. $11\n",
      "Essen vs Springwood, Sunday 2:00 p.m. $11\n",
      "LAWN BOWLS :\n",
      "Tans Town B.C\n",
      "Tans Town vs White Vale, Saturday 9:00 p.m. $10\n",
      "Wake Hill B.C.\n",
      "Wake Hill vs Colls, Saturday 2: 00 p.m. $9\n",
      "\n",
      "Question: According to the passage, the most popular time for the sporting events may be   _  .\n",
      "\n",
      "Options:\n",
      "A) Sat 8:30 pm\n",
      "B) Sun noon\n",
      "C) Sun 2:00 pm\n",
      "D) Sat 2:00 pm\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C D\n",
      "Processed 70 examples, current accuracy: 0.28\n",
      "tensor([5.9605e-08, 5.9605e-08, 3.9339e-06, 1.0133e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Barack Obama became US President in January, 2009. Since then, the world has been watching him closely to see whether he keeps his promises about the economy , foreign policy and health care.\n",
      "But at home, he has also been under pressure from his two daughters to keep his promise: to give them a new dog as a gift for helping him with his election campaign .\n",
      "On Tuesday the nation's first dog, named Bo, came out. It is a six-month-old water dog which is black with a white chest and white paws .\n",
      "\"Bo's got star quality,\" said President Obama as he and his family took a walk with the dog on the White House lawn  in front of reporters.\n",
      "He then joked, \" I finally got a friend. It took some time,\" mentioning a famous saying,\n",
      "\n",
      "Question: Barack Obama is    _    President now.\n",
      "\n",
      "Options:\n",
      "A) French\n",
      "B) British\n",
      "C) Russian\n",
      "D) American\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C D\n",
      "Processed 80 examples, current accuracy: 0.30\n",
      "tensor([5.9605e-08, 5.9605e-08, 3.6359e-06, 9.5367e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: Part-time Waitress\n",
      "Busy cafe needs honest and good-looking waitress for weekends. Must enjoy working with a team and dealing with customers. Call Li Ling at 0732-8536724 after 6 pm.\n",
      "Delivery   Person\n",
      "Young, healthy person able to deliver heavy boxes of books. Must have a driver's license and can carry heavy boxes. We're looking for a person for this position. Call Liu Fang at 0732-7887766 at any time.\n",
      " _ Wanted\n",
      "Kind, hard-working nanny wanted to look after three friendly children. Must be experienced and have childcare quail fications . Please call Chen Yiping at 0732-6774538 between 10 a.m. and 4 p.m\n",
      "\n",
      "Question: These are   _   in the newspaper.\n",
      "\n",
      "Options:\n",
      "A) notices\n",
      "B) ads\n",
      "C) stories\n",
      "D) news\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C B\n",
      "Processed 90 examples, current accuracy: 0.29\n",
      "tensor([5.9605e-08, 5.9605e-08, 2.6226e-06, 2.3246e-06])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: On May 23,1989, Stefania Follini came out from a cave at Carlsbad , New Mexico.She hadn't seen the sun for eighteen and a half weeks .Stefania was in a research program, and the scientists in the program were studying body rhythms  . In this experiment Stefania had spent 130 days in a cave ,30 feet in depth.\n",
      "During her time in the cave, Stefania had been completely alone except for two white mice.Her living place had been very comfortable ,but there had been nothing to feel her the time .She'd had no clock or watches , no television or radio.There had been no natural light and the temperature had always been kept at 21degC\n",
      "\n",
      "Question: Stefania stayed in the cave for a long time because  _  .\n",
      "\n",
      "Options:\n",
      "A) she was asked to do research on mice\n",
      "B) she wanted to experience loneliness\n",
      "C) she was the subject of a study\n",
      "D) she needed to record her life\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C C\n",
      "Processed 100 examples, current accuracy: 0.30\n",
      "tensor([0.0000e+00, 5.9605e-08, 1.7881e-06, 7.7486e-07])\n",
      "\n",
      "     You are a smart question answering model. Answer the question based on the next information, and at the end\n",
      "     you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\n",
      "     Context: When you have a post-office box, the postman doesn't bring letters to you, but you go to the post-office and get your letters and parcels from your box. The box is locked, only you have the key, so the letters and parcels are safe.\n",
      "One day the headmaster of a school wrote to the post-office and asked for a post-office box for his school. He soon got an answer. It said, \"We will give you a post-office box in one month.\"\n",
      "Three months later, the headmaster wrote to the post-office and said, \"Why haven't we got a post-office box yet?\"\n",
      "This was the answer from the post-office:\n",
      "\"Dear sir,\n",
      "We gave you a post-office box two months and wrote to you then to tell you. Here is the key to your box. You will find our letter to you in it.\"\n",
      "\n",
      "Question: Which of the following might not be true?\n",
      "\n",
      "Options:\n",
      "A) If you want to get a post-office box, you must let the post-office know.\n",
      "B) When you get a post-office box, you have to do the work of a postman.\n",
      "C) You go to the post-office to get the key to your box.\n",
      "D) After you get a post-office box, the post man will not send mails to your house.\n",
      "\n",
      "After analyze that, the option i choose between (A, B, C or D) is \n",
      "C B\n",
      "Processed 110 examples, current accuracy: 0.29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      7\u001B[39m x = \u001B[33mf\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[33m You are a smart question answering model. Answer the question based on the next information, and at the end\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[33m you will find the answer options. Choose the best one, only give the letter of the answer which could be A, B, C or D.\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[33m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m     11\u001B[39m x_tokenized = tokenizer(x, padding=\u001B[33m\"\u001B[39m\u001B[33mmax_length\u001B[39m\u001B[33m\"\u001B[39m, truncation=\u001B[38;5;28;01mTrue\u001B[39;00m, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m, max_length=\u001B[32m512\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m out = options_picker(x_tokenized[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m], x_tokenized[\u001B[33m\"\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     13\u001B[39m answer = options[torch.argmax(out)]\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer == y:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Try/pytorch/09_lora/model/options_picker.py:48\u001B[39m, in \u001B[36mOptionsPicker.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask)\u001B[39m\n\u001B[32m     42\u001B[39m logits = \u001B[38;5;28mself\u001B[39m.model(\n\u001B[32m     43\u001B[39m     input_ids=input_ids,\n\u001B[32m     44\u001B[39m     attention_mask=attention_mask,\n\u001B[32m     45\u001B[39m ).logits\n\u001B[32m     47\u001B[39m probs = torch.nn.functional.softmax(logits[\u001B[32m0\u001B[39m, -\u001B[32m1\u001B[39m], dim=-\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m option_ids = \u001B[38;5;28mself\u001B[39m._get_option_ids()\n\u001B[32m     49\u001B[39m option_probs = []\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m option_id \u001B[38;5;129;01min\u001B[39;00m option_ids:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Try/pytorch/09_lora/model/options_picker.py:29\u001B[39m, in \u001B[36mOptionsPicker._get_option_ids\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     27\u001B[39m option_ids = []\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m option \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.options:\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m     inputs = \u001B[38;5;28mself\u001B[39m.tokenizer(option, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m).to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m     30\u001B[39m     option_ids.append(inputs[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m][\u001B[32m0\u001B[39m][\u001B[32m1\u001B[39m].item())\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m option_ids\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Try/pytorch/09_lora/model/llama_3_2_tokenizer.py:30\u001B[39m, in \u001B[36mLlama32Tokenizer.forward\u001B[39m\u001B[34m(self, text, max_length, padding, truncation, return_tensors)\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[32m     18\u001B[39m             text: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m     19\u001B[39m             max_length=\u001B[32m512\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     22\u001B[39m             return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     23\u001B[39m             ):\n\u001B[32m     24\u001B[39m     inputs = \u001B[38;5;28mself\u001B[39m.tokenizer(\n\u001B[32m     25\u001B[39m         text,\n\u001B[32m     26\u001B[39m         max_length=max_length,\n\u001B[32m     27\u001B[39m         padding=padding,\n\u001B[32m     28\u001B[39m         truncation=truncation,\n\u001B[32m     29\u001B[39m         return_tensors=return_tensors,\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m     ).to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m     31\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:821\u001B[39m, in \u001B[36mBatchEncoding.to\u001B[39m\u001B[34m(self, device, non_blocking)\u001B[39m\n\u001B[32m    816\u001B[39m \u001B[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001B[39;00m\n\u001B[32m    817\u001B[39m \u001B[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001B[39;00m\n\u001B[32m    818\u001B[39m \u001B[38;5;66;03m# into a HalfTensor\u001B[39;00m\n\u001B[32m    819\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m is_torch_device(device) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mint\u001B[39m):\n\u001B[32m    820\u001B[39m     \u001B[38;5;28mself\u001B[39m.data = {\n\u001B[32m--> \u001B[39m\u001B[32m821\u001B[39m         k: v.to(device=device, non_blocking=non_blocking) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, torch.Tensor) \u001B[38;5;28;01melse\u001B[39;00m v\n\u001B[32m    822\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.data.items()\n\u001B[32m    823\u001B[39m     }\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    825\u001B[39m     logger.warning(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAttempting to cast a BatchEncoding to type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(device)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. This is not supported.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:22.469188Z",
     "start_time": "2025-05-11T02:00:22.464937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = data_prompted[90]\n",
    "\n"
   ],
   "id": "575eeb884f68fd17",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:22.635601Z",
     "start_time": "2025-05-11T02:00:22.630511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = f\"\"\"You are a smart question answering model. Answer the question based on the next information, and at the end you should pick the right answer. Choose the best one, only give the letter of the answer which could be A, B, C or D. You must give your answer in a single letter.\n",
    "     {x}\"\"\"\n",
    "x, y"
   ],
   "id": "5d3058de89ec2434",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"You are a smart question answering model. Answer the question based on the next information, and at the end you should pick the right answer. Choose the best one, only give the letter of the answer which could be A, B, C or D. You must give your answer in a single letter.\\n     Context: Part-time Waitress\\nBusy cafe needs honest and good-looking waitress for weekends. Must enjoy working with a team and dealing with customers. Call Li Ling at 0732-8536724 after 6 pm.\\nDelivery   Person\\nYoung, healthy person able to deliver heavy boxes of books. Must have a driver's license and can carry heavy boxes. We're looking for a person for this position. Call Liu Fang at 0732-7887766 at any time.\\n _ Wanted\\nKind, hard-working nanny wanted to look after three friendly children. Must be experienced and have childcare quail fications . Please call Chen Yiping at 0732-6774538 between 10 a.m. and 4 p.m\\n\\nQuestion: These are   _   in the newspaper.\\n\\nOptions:\\nA) notices\\nB) ads\\nC) stories\\nD) news\\n\\nAfter analyze that, the option i choose between (A, B, C or D) is \",\n",
       " 'B')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:32.382585Z",
     "start_time": "2025-05-11T02:00:22.865095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tokenized = tokenizer(x, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "generation = model.model.generate(\n",
    "    input_ids=x_tokenized[\"input_ids\"],\n",
    "    attention_mask=x_tokenized[\"attention_mask\"],\n",
    "    max_length=1024,\n",
    ")"
   ],
   "id": "64d7eafc191fc817",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:32.391776Z",
     "start_time": "2025-05-11T02:00:32.387681Z"
    }
   },
   "cell_type": "code",
   "source": "out = tokenizer.decode(generation[0])",
   "id": "cbc02f361708def1",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:32.446008Z",
     "start_time": "2025-05-11T02:00:32.441754Z"
    }
   },
   "cell_type": "code",
   "source": "out",
   "id": "e054c63ecfd50f99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a smart question answering model. Answer the question based on the next information, and at the end you should pick the right answer. Choose the best one, only give the letter of the answer which could be A, B, C or D. You must give your answer in a single letter.\\n     Context: Part-time Waitress\\nBusy cafe needs honest and good-looking waitress for weekends. Must enjoy working with a team and dealing with customers. Call Li Ling at 0732-8536724 after 6 pm.\\nDelivery   Person\\nYoung, healthy person able to deliver heavy boxes of books. Must have a driver's license and can carry heavy boxes. We're looking for a person for this position. Call Liu Fang at 0732-7887766 at any time.\\n _ Wanted\\nKind, hard-working nanny wanted to look after three friendly children. Must be experienced and have childcare quail fications. Please call Chen Yiping at 0732-6774538 between 10 a.m. and 4 p.m\\n\\nQuestion: These are   _   in the newspaper.\\n\\nOptions:\\nA) notices\\nB) ads\\nC) stories\\nD) news\\n\\nAfter analyze that, the option i choose between (A, B, C or D) is Question: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: the use of contraceptives\\nOption B: the use of alcohol\\nOption C: the use of cigarettes\\nOption D: the use of oral contraceptives\\n\\nQuestion: Which of the following statements is true?\\n\\nOption A: The use of oral contraceptives is the only way to prevent pregnancy.\\nOption B: The use of oral contraceptives is the only way to prevent cancer.\\nOption C: The use of oral contraceptives is the only way to prevent cancer.\\nOption D: The use of oral contraceptives is the only way to prevent cancer and pregnancy.\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is the most likely reason for the high incidence of cancer in the population of women?\\n\\nOption A: The use of contraceptives\\nOption B: The use of alcohol\\nOption C: The use of cigarettes\\nOption D: The use of oral contraceptives\\n\\nQuestion: Which of the following is\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:32.558580Z",
     "start_time": "2025-05-11T02:00:32.555238Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "685ec839091db9fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T02:00:32.615155Z",
     "start_time": "2025-05-11T02:00:32.610658Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "847efaf57d655d14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9bf8157999e19450"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
